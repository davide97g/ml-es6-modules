/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./src/js/index.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./src/js/drawer.js":
/*!**************************!*\
  !*** ./src/js/drawer.js ***!
  \**************************/
/*! exports provided: drawer, master_drawer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"drawer\", function() { return drawer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"master_drawer\", function() { return master_drawer; });\nconst drawer = function(algorithm, canvas, options) {\r\n  this.algorithm = algorithm;\r\n  this.ctx = canvas.getContext(\"2d\");\r\n  this.WIDTH = canvas.width;\r\n  this.HEIGHT = canvas.height;\r\n  this.options = options || { margin: \"soft\" };\r\n  this.ss = options.ss || 20;\r\n  this.density = options.density || 3;\r\n};\r\n\r\ndrawer.prototype = {\r\n  setAlgorithm: function(algorithm) {\r\n    this.algorithm = algorithm;\r\n  },\r\n  setOptions: function(options) {\r\n    this.options = options || {};\r\n  },\r\n  draw: function(points, labels) {\r\n    //clear\r\n    this.ctx.clearRect(0, 0, this.WIDTH, this.HEIGHT);\r\n    //draw grid\r\n    this.drawGrid();\r\n    //draw axes\r\n    this.drawAxes();\r\n    //draw data points\r\n    this.drawPoints(points, labels);\r\n    //draw test points\r\n    //@TODO draw test function\r\n  },\r\n  drawGrid: function() {\r\n    //draw screen\r\n    for (let x = 0.0; x <= this.WIDTH; x += this.density) {\r\n      for (let y = 0.0; y <= this.HEIGHT; y += this.density) {\r\n        let predicted_class = this.algorithm.predictClass([\r\n          (x - this.WIDTH / 2) / this.ss,\r\n          (y - this.HEIGHT / 2) / this.ss\r\n        ]);\r\n        let predicted_value = 0;\r\n        if (this.options.margin === \"soft\")\r\n          predicted_value = this.algorithm.predict([\r\n            (x - this.WIDTH / 2) / this.ss,\r\n            (y - this.HEIGHT / 2) / this.ss\r\n          ]);\r\n        else predicted_value = predicted_class;\r\n        this.ctx.fillStyle = getColor(predicted_value, predicted_class);\r\n        this.ctx.fillRect(\r\n          x - this.density / 2 - 1,\r\n          y - this.density - 1,\r\n          this.density + 2,\r\n          this.density + 2\r\n        );\r\n      }\r\n    }\r\n  },\r\n  drawAxes: function() {\r\n    this.ctx.beginPath();\r\n    this.ctx.strokeStyle = \"rgb(50,50,50)\";\r\n    this.ctx.lineWidth = 1;\r\n    this.ctx.moveTo(0, this.HEIGHT / 2);\r\n    this.ctx.lineTo(this.WIDTH, this.HEIGHT / 2);\r\n    this.ctx.moveTo(this.WIDTH / 2, 0);\r\n    this.ctx.lineTo(this.WIDTH / 2, this.HEIGHT);\r\n    this.ctx.stroke();\r\n  },\r\n  drawPoints: function(points, labels) {\r\n    let radius = 6;\r\n    for (let i = 0; i < points.length; i++) {\r\n      let prediction = this.algorithm.predictClass(points[i]);\r\n      this.ctx.fillStyle = getPointColor(prediction, labels[i]);\r\n      this.drawCircle(\r\n        points[i][0] * this.ss + this.WIDTH / 2,\r\n        points[i][1] * this.ss + this.HEIGHT / 2,\r\n        radius\r\n      );\r\n    }\r\n  },\r\n  drawCircle: function(x, y, r) {\r\n    this.ctx.beginPath();\r\n    this.ctx.arc(x, y, r, 0, Math.PI * 2, true);\r\n    this.ctx.closePath();\r\n    this.ctx.stroke();\r\n    this.ctx.fill();\r\n  }\r\n};\r\n\r\nconst master_drawer = function(canvas, callback, options) {\r\n  this.ctx = canvas.getContext(\"2d\");\r\n  canvas.addEventListener(\"click\", e => callback(eventClick(canvas, e)));\r\n  this.WIDTH = canvas.width;\r\n  this.HEIGHT = canvas.height;\r\n  this.options = options;\r\n  this.ss = options.ss || 20;\r\n  this.density = options.density || 3;\r\n};\r\n\r\nmaster_drawer.prototype = {\r\n  draw: function(points, labels) {\r\n    //clear\r\n    this.ctx.clearRect(0, 0, this.WIDTH, this.HEIGHT);\r\n    //draw axes\r\n    this.drawAxes();\r\n    //draw data points\r\n    this.drawPoints(points, labels);\r\n    //draw test points\r\n    //@TODO draw test function\r\n  },\r\n  drawAxes: function() {\r\n    this.ctx.beginPath();\r\n    this.ctx.strokeStyle = \"rgb(50,50,50)\";\r\n    this.ctx.lineWidth = 1;\r\n    this.ctx.moveTo(0, this.HEIGHT / 2);\r\n    this.ctx.lineTo(this.WIDTH, this.HEIGHT / 2);\r\n    this.ctx.moveTo(this.WIDTH / 2, 0);\r\n    this.ctx.lineTo(this.WIDTH / 2, this.HEIGHT);\r\n    this.ctx.stroke();\r\n  },\r\n  drawPoints: function(points, labels) {\r\n    let radius = 6;\r\n    for (let i = 0; i < points.length; i++) {\r\n      this.ctx.fillStyle = getPointColor(labels[i], labels[i]);\r\n      this.drawCircle(\r\n        points[i][0] * this.ss + this.WIDTH / 2,\r\n        points[i][1] * this.ss + this.HEIGHT / 2,\r\n        radius\r\n      );\r\n    }\r\n  },\r\n  drawCircle: function(x, y, r) {\r\n    this.ctx.beginPath();\r\n    this.ctx.arc(x, y, r, 0, Math.PI * 2, true);\r\n    this.ctx.closePath();\r\n    this.ctx.stroke();\r\n    this.ctx.fill();\r\n  }\r\n};\r\n\r\nfunction eventClick(canvas, e) {\r\n  //get position of cursor relative to top left of canvas\r\n  let x = 0;\r\n  let y = 0;\r\n  if (e.pageX || e.pageY) {\r\n    x = e.pageX;\r\n    y = e.pageY;\r\n  }\r\n  x -= canvas.offsetLeft;\r\n  y -= canvas.offsetTop;\r\n  return {\r\n    x: x,\r\n    y: y,\r\n    shiftPressed: e.shiftKey,\r\n    ctrlPressed: e.ctrlKey\r\n  };\r\n}\r\n\r\nfunction getPointColor(predicted, real) {\r\n  if (predicted * real > 0) {\r\n    if (predicted > 0) return \"rgb(150,250,150)\";\r\n    else return \"rgb(250,150,150)\";\r\n  } else {\r\n    if (predicted > 0) return \"rgb(105,147,250)\";\r\n    else return \"rgb(240,226,63)\";\r\n  }\r\n}\r\n\r\nfunction getColor(prediction, real) {\r\n  let ri, gi;\r\n  if (prediction < 0) {\r\n    // less red 250-150\r\n    ri = 150 - 100 * prediction; //with value = -1 ===> ri = 250\r\n    gi = 250 + 100 * prediction; //with value = -1 ===> gi = 150\r\n  } else {\r\n    //less green 150-250\r\n    ri = 250 - 100 * prediction; //with value = 1 ===> ri = 150\r\n    gi = 150 + 100 * prediction; //with value = 1 ===> gi = 250\r\n  }\r\n  if (real > 0) gi += 5;\r\n  else ri += 35;\r\n  return \"rgb(\" + Math.floor(ri) + \",\" + Math.floor(gi) + \",150)\";\r\n}\r\n\n\n//# sourceURL=webpack:///./src/js/drawer.js?");

/***/ }),

/***/ "./src/js/index.js":
/*!*************************!*\
  !*** ./src/js/index.js ***!
  \*************************/
/*! no exports provided */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _logreg_logreg__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./logreg/logreg */ \"./src/js/logreg/logreg.js\");\n/* harmony import */ var _svm_svm__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./svm/svm */ \"./src/js/svm/svm.js\");\n/* harmony import */ var _knn_knn__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./knn/knn */ \"./src/js/knn/knn.js\");\n/* harmony import */ var _rbf_rbf__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./rbf/rbf */ \"./src/js/rbf/rbf.js\");\n/* harmony import */ var _randf_randf__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./randf/randf */ \"./src/js/randf/randf.js\");\n/* harmony import */ var _drawer__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./drawer */ \"./src/js/drawer.js\");\n/* harmony import */ var _nn_nn__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./nn/nn */ \"./src/js/nn/nn.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nlet radioXY = document.getElementById(\"xy\");\r\nradioXY.addEventListener(\"click\", () => {\r\n  data = selectPredictors(multi, 0, 1);\r\n  drawers.forEach(drawer => drawer.draw(data, labels));\r\n});\r\n\r\nlet radioYZ = document.getElementById(\"yz\");\r\nradioYZ.addEventListener(\"click\", () => {\r\n  data = selectPredictors(multi, 1, 2);\r\n  drawers.forEach(drawer => drawer.draw(data, labels));\r\n});\r\n\r\nlet radioXZ = document.getElementById(\"xz\");\r\nradioXZ.addEventListener(\"click\", () => {\r\n  data = selectPredictors(multi, 0, 2);\r\n  drawers.forEach(drawer => drawer.draw(data, labels));\r\n});\r\n\r\nlet MARGIN = document.getElementById(\"margin\");\r\nMARGIN.addEventListener(\"click\", () => {\r\n  let margin;\r\n  if (MARGIN.checked) margin = \"soft\";\r\n  else margin = \"hard\";\r\n  drawers.forEach(drawer => drawer.setOptions({ margin: margin }));\r\n  drawers.forEach(drawer => drawer.draw(data, labels));\r\n});\r\n\r\nlet multi = [\r\n  [1, 0, 2],\r\n  [2, 3, 4],\r\n  [5, 4, 6],\r\n  [2, 7, 5],\r\n  [0, 3, 7],\r\n  [-1, 0, -2],\r\n  [-3, -4, -4],\r\n  [-2, -2, -1],\r\n  [-1, -1, -3],\r\n  [-5, -2, -5]\r\n];\r\n\r\nlet data = selectPredictors(multi, 0, 1);\r\nlet labels = [1, 1, 1, 1, 1, -1, -1, -1, -1, -1];\r\n\r\nlet svm_linear = new _svm_svm__WEBPACK_IMPORTED_MODULE_1__[\"SVM\"]();\r\nlet svm_linear_options = {\r\n  kernel: \"linear\",\r\n  degree: 1,\r\n  influence: 0,\r\n  C: 1,\r\n  SSCA: false,\r\n  UB: 0.5,\r\n  memoize: true,\r\n  input_functions: [],\r\n  karpathy: true,\r\n  timer: null\r\n};\r\nsvm_linear.train(data, labels, svm_linear_options);\r\n\r\nlet svm_poly = new _svm_svm__WEBPACK_IMPORTED_MODULE_1__[\"SVM\"]();\r\nlet svm_poly_options = {\r\n  kernel: \"poly\",\r\n  degree: 2,\r\n  influence: 0,\r\n  C: 1,\r\n  SSCA: false,\r\n  UB: 0.5,\r\n  memoize: true,\r\n  input_functions: [],\r\n  karpathy: true,\r\n  timer: null\r\n};\r\nsvm_poly.train(data, labels, svm_poly_options);\r\n\r\nlet svm_rbf = new _svm_svm__WEBPACK_IMPORTED_MODULE_1__[\"SVM\"]();\r\nlet svm_rbf_options = {\r\n  kernel: \"rbf\",\r\n  degree: 2,\r\n  influence: 0,\r\n  C: 1,\r\n  SSCA: false,\r\n  UB: 0.5,\r\n  memoize: true,\r\n  input_functions: [],\r\n  karpathy: true,\r\n  timer: null\r\n};\r\nsvm_rbf.train(data, labels, svm_rbf_options);\r\n\r\nlet knn = new _knn_knn__WEBPACK_IMPORTED_MODULE_2__[\"KNN\"]();\r\nlet knn_options = {\r\n  k: 3,\r\n  distance: \"minkowski\",\r\n  p: 1.5\r\n};\r\nknn.train(data, labels, knn_options);\r\n\r\nlet rbf = new _rbf_rbf__WEBPACK_IMPORTED_MODULE_3__[\"RBF\"]();\r\nlet rbf_options = {\r\n  epsilon: 0.1,\r\n  rbfSigma: 0.5\r\n};\r\nrbf.train(data, labels, rbf_options);\r\n\r\nlet randf = new _randf_randf__WEBPACK_IMPORTED_MODULE_4__[\"RandomForest\"]();\r\nlet randf_options = {\r\n  numTrees: 100\r\n};\r\nrandf.train(data, labels, randf_options);\r\n\r\nlet logreg = new _logreg_logreg__WEBPACK_IMPORTED_MODULE_0__[\"LogisticRegression\"]();\r\nlet logreg_options = {};\r\nlogreg.train(data, labels, logreg_options);\r\n\r\nlet nn = new _nn_nn__WEBPACK_IMPORTED_MODULE_6__[\"NeuralNet\"]();\r\nlet nn_options = {};\r\nnn.train(data, labels, nn_options);\r\n\r\n// update canvas on mouseclick\r\nlet mouseClick = ({ x, y, shiftPressed }) => {\r\n  let t0 = performance.now();\r\n  // store point\r\n  data.push([\r\n    (x - master.WIDTH / 2) / master.ss,\r\n    (y - master.HEIGHT / 2) / master.ss\r\n  ]);\r\n  labels.push(shiftPressed ? 1 : -1);\r\n\r\n  // draw master\r\n  master.draw(data, labels);\r\n\r\n  // train\r\n  training(data, labels);\r\n\r\n  // draw all\r\n  drawers.forEach(drawer => drawer.draw(data, labels));\r\n\r\n  let t1 = performance.now();\r\n  console.info(t1 - t0 + \" ms\");\r\n};\r\n\r\nlet drawers = [];\r\n//master canvas with mouse click event listener\r\nlet master_canvas = document.getElementById(\"draw-canvas-test\");\r\nlet master = new _drawer__WEBPACK_IMPORTED_MODULE_5__[\"master_drawer\"](master_canvas, mouseClick, {});\r\nmaster.draw(data, labels);\r\n\r\n//create the other drawers\r\ndrawers.push(\r\n  new _drawer__WEBPACK_IMPORTED_MODULE_5__[\"drawer\"](svm_linear, document.getElementById(\"svm-linear-canvas\"), {\r\n    margin: \"soft\"\r\n  })\r\n);\r\ndrawers.push(\r\n  new _drawer__WEBPACK_IMPORTED_MODULE_5__[\"drawer\"](svm_poly, document.getElementById(\"svm-poly-canvas\"), {\r\n    margin: \"soft\"\r\n  })\r\n);\r\ndrawers.push(\r\n  new _drawer__WEBPACK_IMPORTED_MODULE_5__[\"drawer\"](svm_rbf, document.getElementById(\"svm-rbf-canvas\"), {\r\n    margin: \"soft\"\r\n  })\r\n);\r\ndrawers.push(\r\n  new _drawer__WEBPACK_IMPORTED_MODULE_5__[\"drawer\"](knn, document.getElementById(\"knn-canvas\"), { margin: \"soft\" })\r\n);\r\ndrawers.push(\r\n  new _drawer__WEBPACK_IMPORTED_MODULE_5__[\"drawer\"](rbf, document.getElementById(\"rbf-canvas\"), { margin: \"soft\" })\r\n);\r\ndrawers.push(\r\n  new _drawer__WEBPACK_IMPORTED_MODULE_5__[\"drawer\"](randf, document.getElementById(\"randf-canvas\"), { margin: \"soft\" })\r\n);\r\ndrawers.push(\r\n  new _drawer__WEBPACK_IMPORTED_MODULE_5__[\"drawer\"](logreg, document.getElementById(\"logreg-canvas\"), {\r\n    margin: \"soft\"\r\n  })\r\n);\r\ndrawers.push(\r\n  new _drawer__WEBPACK_IMPORTED_MODULE_5__[\"drawer\"](nn, document.getElementById(\"nn-canvas\"), { margin: \"soft\" })\r\n);\r\n\r\n//draw all\r\ndrawers.forEach(drawer => drawer.draw(data, labels));\r\n\r\n//_______________\r\n\r\nfunction training(data, labels) {\r\n  svm_linear.train(data, labels, svm_linear_options);\r\n  svm_poly.train(data, labels, svm_poly_options);\r\n  svm_rbf.train(data, labels, svm_rbf_options);\r\n  knn.train(data, labels, knn_options);\r\n  rbf.train(data, labels, rbf_options);\r\n  randf.train(data, labels, randf_options);\r\n  logreg.train(data, labels, logreg_options);\r\n  nn.train(data, labels, nn_options);\r\n}\r\n\r\nfunction selectPredictors(data, chosen1, chosen2) {\r\n  let predictors = [];\r\n  data.forEach(point => predictors.push([point[chosen1], point[chosen2]]));\r\n  return predictors;\r\n}\r\n\n\n//# sourceURL=webpack:///./src/js/index.js?");

/***/ }),

/***/ "./src/js/knn/distances.js":
/*!*********************************!*\
  !*** ./src/js/knn/distances.js ***!
  \*********************************/
/*! exports provided: Distances */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Distances\", function() { return Distances; });\n/**\r\n *\r\n * @description\r\n * Class used to handle distances functions\r\n * @example\r\n * //new instance\r\n * let distances = new Distances();\r\n * //define two points\r\n * let point1 = {x:1,y:3};\r\n * let point2 = {x:4,y:-2};\r\n * //minkowski distance from two points\r\n * let minkowski_distance = distances.minkowski(point1,point2);\r\n * //chebyshev distance from two points\r\n * let chebyshev_distance = distances.chebyshev(point1,point2);\r\n * //mahalanobis distance from two points\r\n * let mahalanobis_distance = distances.mahalanobis(point1,point2);\r\n * //setting the grade for minkowski\r\n * distances.setMinkowskiDegree(2);\r\n */\r\nconst Distances = function() {\r\n\tthis.p = 1;\r\n\tthis.data = [];\r\n\tthis.variance = 0;\r\n\tthis.default = function() {};\r\n};\r\n\r\nDistances.prototype = {\r\n\t/**\r\n     * Sets the dataset and calculate the variance\r\n     * @param data {data} dataset to be used for the distances calculations\r\n     */\r\n\tsetDataSet: function(data) {\r\n\t\tthis.data = data;\r\n\t\tthis.variance = variance(data);\r\n\t},\r\n\r\n\t/**\r\n\t * Set the default function for the distance calculation\r\n\t * @param {String} algorithm \r\n\t */\r\n\tsetDefault: function(algorithm) {\r\n\t\tif (algorithm === 'minkowski') this.default = this.minkowski;\r\n\t\telse if (algorithm === 'chebyshev') this.default = this.chebyshev;\r\n\t\telse if (algorithm === 'mahalanobis') this.default = this.mahalanobis;\r\n\t\telse this.default = this.minkowski;\r\n\t},\r\n\r\n\t/**\r\n\t * Returns the distance between two points using the default algorithm\r\n\t * @param point1 {point} first point\r\n     * @param point2 {point} second point\r\n     * @returns {number} distance\r\n\t */\r\n\tof: function(point1, point2) {\r\n\t\ttry {\r\n\t\t\treturn this.default(point1, point2);\r\n\t\t} catch (e) {\r\n\t\t\tconsole.warn(e);\r\n\t\t}\r\n\t},\r\n\r\n\t/**\r\n     * Sets the degree of the minkowski distance\r\n     * @param p {Number} the degree for minkowski distance\r\n     */\r\n\tsetMinkowskiDegree: function(p) {\r\n\t\tthis.p = p || this.p;\r\n\t\tif (this.p < 1) this.p = 1;\r\n\t},\r\n\r\n\t/**\r\n     * Returns the minkowski distance between two points\r\n     * @param point1 {point} first point\r\n     * @param point2 {point} second point\r\n     * @returns {number} minkowski distance\r\n     */\r\n\tminkowski: function(point1, point2) {\r\n\t\treturn Math.pow(\r\n\t\t\tMath.pow(Math.abs(point1.x - point2.x), this.p) + Math.pow(Math.abs(point1.y - point2.y), this.p),\r\n\t\t\t1 / this.p\r\n\t\t);\r\n\t},\r\n\r\n\t/**\r\n     * Returns the chebyshev distance between two points\r\n     * @param point1 {point} first point\r\n     * @param point2 {point} second point\r\n     * @returns {number} chebyshev distance between the two points\r\n     */\r\n\tchebyshev: function(point1, point2) {\r\n\t\treturn Math.max(Math.abs(point2.x - point1.x), Math.abs(point2.y - point1.y));\r\n\t},\r\n\r\n\t/**\r\n     * Returns the mahalanobis distance between two points\r\n     * @param point1 {point} first point\r\n     * @param point2 {point} second point\r\n     * @returns {number} mahalanobis distance between the two points\r\n     */\r\n\tmahalanobis: function(point1, point2) {\r\n\t\tif (this.data.length === 0) throw 'no data';\r\n\t\tlet sum =\r\n\t\t\tMath.pow(point1.x - point2.x, 2) / Math.pow(this.variance.x, 2) +\r\n\t\t\tMath.pow(point1.y - point2.y, 2) / Math.pow(this.variance.y, 2);\r\n\t\treturn Math.sqrt(sum);\r\n\t}\r\n};\r\n\r\nfunction variance(data) {\r\n\tlet avg = average(data);\r\n\tlet variance = { x: 0, y: 0 };\r\n\tlet N = data.length;\r\n\tfor (let j = 0; j < N; j++) {\r\n\t\tvariance.x += Math.pow(data[j][0] - avg[0], 2);\r\n\t\tvariance.y += Math.pow(data[j][1] - avg[1], 2);\r\n\t}\r\n\tvariance.x = Math.sqrt(variance.x / N);\r\n\tvariance.y = Math.sqrt(variance.y / N);\r\n\treturn variance;\r\n}\r\n\r\nfunction average(data) {\r\n\tlet avg = [ 0, 0 ];\r\n\tlet N = data.length;\r\n\tfor (let i = 0; i < N; i++) {\r\n\t\tavg[0] += data[i][0];\r\n\t\tavg[1] += data[i][1];\r\n\t}\r\n\tavg[0] /= N;\r\n\tavg[1] /= N;\r\n\treturn avg;\r\n}\r\n\n\n//# sourceURL=webpack:///./src/js/knn/distances.js?");

/***/ }),

/***/ "./src/js/knn/knn.js":
/*!***************************!*\
  !*** ./src/js/knn/knn.js ***!
  \***************************/
/*! exports provided: KNN */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"KNN\", function() { return KNN; });\n/* harmony import */ var _distances_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./distances.js */ \"./src/js/knn/distances.js\");\n\r\nconst KNN = function() {};\r\nKNN.prototype = {\r\n  train: function(data, labels, options) {\r\n    this.data = data;\r\n    this.labels = labels;\r\n    this.options = options;\r\n    this.distances = new _distances_js__WEBPACK_IMPORTED_MODULE_0__[\"Distances\"]();\r\n    this.distances.setDataSet(data);\r\n    let distance = this.options.distance || \"minkowski\";\r\n    this.distances.setDefault(distance);\r\n    if (distance === \"minkowski\") {\r\n      let p = this.options.p || 1;\r\n      this.distances.setMinkowskiDegree(p);\r\n    }\r\n  },\r\n  predict: function(point) {\r\n    return (this.knn(point, this.options.k) + 1) / 2;\r\n  },\r\n  predictClass: function(point) {\r\n    return this.knn(point, this.options.k) > 0 ? 1 : -1;\r\n  },\r\n  knn: function(point, k) {\r\n    k = k || 1;\r\n    if (k < 1) k = 1;\r\n    if (k > this.data.length) {\r\n      console.warn(\r\n        \"need more data: KNN with K: \" + k + \" and #data: \" + this.data.length\r\n      );\r\n      return 0;\r\n    }\r\n    let nearest = new Array(k);\r\n    for (let i = 0; i < k; i++) {\r\n      nearest[i] = {};\r\n      nearest[i].distance = this.distances.of(\r\n        { x: point[0], y: point[1] },\r\n        { x: this.data[i][0], y: this.data[i][1] }\r\n      );\r\n      nearest[i].label = this.labels[i];\r\n    }\r\n\r\n    nearest.sort(function(a, b) {\r\n      return b.distance - a.distance;\r\n    }); //ordino decrescente\r\n\r\n    let d = 0;\r\n\r\n    for (let i = k; i < this.data.length; i++) {\r\n      d = this.distances.of(\r\n        { x: point[0], y: point[1] },\r\n        { x: this.data[i][0], y: this.data[i][1] }\r\n      );\r\n      if (nearest[0].distance > d) {\r\n        //se è più distante il più distante dei nearest, aggiorno la lista\r\n        nearest[0].distance = d;\r\n        nearest[0].label = this.labels[i];\r\n        nearest.sort((a, b) => b.distance - a.distance); //ordino decrescente\r\n      }\r\n    }\r\n\r\n    let c = 0;\r\n    let class1 = 0;\r\n    let class2 = 0;\r\n    for (let i = 0; i < k; i++) {\r\n      c += nearest[i].label;\r\n      if (nearest[i].label === 1) class2++;\r\n      else class1++;\r\n    }\r\n    if (c === 0) return 0;\r\n    if (c > 0) return class2 / k;\r\n    //greenish\r\n    else return -class1 / k; //reddish\r\n  }\r\n};\r\n\n\n//# sourceURL=webpack:///./src/js/knn/knn.js?");

/***/ }),

/***/ "./src/js/logreg/logreg.js":
/*!*********************************!*\
  !*** ./src/js/logreg/logreg.js ***!
  \*********************************/
/*! exports provided: LOGREG, LinearRegression, LogisticRegression, MultiClassLogistic */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LOGREG\", function() { return LOGREG; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LinearRegression\", function() { return LinearRegression; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LogisticRegression\", function() { return LogisticRegression; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MultiClassLogistic\", function() { return MultiClassLogistic; });\nconst LOGREG = function() {};\r\nLOGREG.prototype = {\r\n\ttrain: function(data, labels, options) {\r\n\t\tconsole.info('trained');\r\n\t},\r\n\tpredict: function(point) {},\r\n\tpredictClass: function(point) {}\r\n};\r\n\r\nconst LinearRegression = function(config) {\r\n\tconfig = config || {};\r\n\r\n\tif (!config.iterations) {\r\n\t\tconfig.iterations = 1000;\r\n\t}\r\n\tif (!config.alpha) {\r\n\t\tconfig.alpha = 0.001;\r\n\t}\r\n\tif (!config.lambda) {\r\n\t\tconfig.lambda = 0.0;\r\n\t}\r\n\tif (!config.trace) {\r\n\t\tconfig.trace = false;\r\n\t}\r\n\r\n\tthis.iterations = config.iterations;\r\n\tthis.alpha = config.alpha;\r\n\tthis.lambda = config.lambda;\r\n\tthis.trace = config.trace;\r\n};\r\n\r\nLinearRegression.prototype.fit = function(data) {\r\n\tlet N = data.length,\r\n\t\tX = [],\r\n\t\tY = [];\r\n\tthis.dim = data[0].length;\r\n\r\n\tfor (let i = 0; i < N; ++i) {\r\n\t\tlet row = data[i];\r\n\t\tlet x_i = [];\r\n\t\tlet y_i = row[row.length - 1];\r\n\t\tx_i.push(1.0);\r\n\t\tfor (let j = 0; j < row.length - 1; ++j) {\r\n\t\t\tx_i.push(row[j]);\r\n\t\t}\r\n\t\tY.push(y_i);\r\n\t\tX.push(x_i);\r\n\t}\r\n\r\n\tthis.theta = [];\r\n\r\n\tfor (let d = 0; d < this.dim; ++d) {\r\n\t\tthis.theta.push(0.0);\r\n\t}\r\n\r\n\tfor (let k = 0; k < this.iterations; ++k) {\r\n\t\tlet Vx = this.grad(X, Y, this.theta);\r\n\r\n\t\tfor (let d = 0; d < this.dim; ++d) {\r\n\t\t\tthis.theta[d] = this.theta[d] - this.alpha * Vx[d];\r\n\t\t}\r\n\r\n\t\tif (this.trace) {\r\n\t\t\tconsole.log('cost at iteration ' + k + ': ' + this.cost(X, Y, this.theta));\r\n\t\t}\r\n\t}\r\n\r\n\treturn {\r\n\t\ttheta: this.theta,\r\n\t\tdim: this.dim,\r\n\t\tcost: this.cost(X, Y, this.theta),\r\n\t\tconfig: {\r\n\t\t\talpha: this.alpha,\r\n\t\t\tlambda: this.lambda,\r\n\t\t\titerations: this.iterations\r\n\t\t}\r\n\t};\r\n};\r\n\r\nLinearRegression.prototype.grad = function(X, Y, theta) {\r\n\tlet N = X.length;\r\n\r\n\tlet Vtheta = [];\r\n\r\n\tfor (let d = 0; d < this.dim; ++d) {\r\n\t\tlet g = 0;\r\n\t\tfor (let i = 0; i < N; ++i) {\r\n\t\t\tlet x_i = X[i];\r\n\t\t\tlet y_i = Y[i];\r\n\r\n\t\t\tlet predicted = this.h(x_i, theta);\r\n\r\n\t\t\tg += (predicted - y_i) * x_i[d];\r\n\t\t}\r\n\r\n\t\tg = (g + this.lambda * theta[d]) / N;\r\n\r\n\t\tVtheta.push(g);\r\n\t}\r\n\r\n\treturn Vtheta;\r\n};\r\n\r\nLinearRegression.prototype.h = function(x_i, theta) {\r\n\tlet predicted = 0.0;\r\n\tfor (let d = 0; d < this.dim; ++d) {\r\n\t\tpredicted += x_i[d] * theta[d];\r\n\t}\r\n\treturn predicted;\r\n};\r\n\r\nLinearRegression.prototype.cost = function(X, Y, theta) {\r\n\tlet N = X.length;\r\n\tlet cost = 0;\r\n\tfor (let i = 0; i < N; ++i) {\r\n\t\tlet x_i = X[i];\r\n\t\tlet predicted = this.h(x_i, theta);\r\n\t\tcost += (predicted - Y[i]) * (predicted - Y[i]);\r\n\t}\r\n\r\n\tfor (let d = 0; d < this.dim; ++d) {\r\n\t\tcost += this.lambda * theta[d] * theta[d];\r\n\t}\r\n\r\n\treturn cost / (2.0 * N);\r\n};\r\n\r\nLinearRegression.prototype.transform = function(x) {\r\n\tif (x[0].length) {\r\n\t\t// x is a matrix\r\n\t\tlet predicted_array = [];\r\n\t\tfor (let i = 0; i < x.length; ++i) {\r\n\t\t\tlet predicted = this.transform(x[i]);\r\n\t\t\tpredicted_array.push(predicted);\r\n\t\t}\r\n\t\treturn predicted_array;\r\n\t}\r\n\r\n\t// x is a row vector\r\n\tlet x_i = [];\r\n\tx_i.push(1.0);\r\n\tfor (let j = 0; j < x.length; ++j) {\r\n\t\tx_i.push(x[j]);\r\n\t}\r\n\treturn this.h(x_i, this.theta);\r\n};\r\n\r\n//_________________Logistic Regression__________________\r\n\r\nconst LogisticRegression = function(import_config) {\r\n\tlet config = import_config || {};\r\n\tif (!config.alpha) {\r\n\t\tconfig.alpha = 0.001;\r\n\t}\r\n\tif (!config.iterations) {\r\n\t\tconfig.iterations = 100;\r\n\t}\r\n\tif (!config.lambda) {\r\n\t\tconfig.lambda = 0;\r\n\t}\r\n\tthis.alpha = config.alpha;\r\n\tthis.lambda = config.lambda;\r\n\tthis.iterations = config.iterations;\r\n};\r\n\r\nLogisticRegression.prototype.train = function(data, labels, options) {\r\n\tlet config = options || {};\r\n\tif (!config.alpha) {\r\n\t\tconfig.alpha = 0.001;\r\n\t}\r\n\tif (!config.iterations) {\r\n\t\tconfig.iterations = 100;\r\n\t}\r\n\tif (!config.lambda) {\r\n\t\tconfig.lambda = 0;\r\n\t}\r\n\tthis.alpha = config.alpha;\r\n\tthis.lambda = config.lambda;\r\n\tthis.iterations = config.iterations;\r\n\r\n\tlet data_labels = [];\r\n\tfor (let i = 0; i < data.length; i++) {\r\n\t\tdata_labels.push(data[i].concat(labels[i]));\r\n\t}\r\n\tthis.fit(data_labels);\r\n};\r\n\r\nLogisticRegression.prototype.fit = function(data) {\r\n\tthis.dim = data[0].length;\r\n\tlet N = data.length;\r\n\r\n\tlet X = [];\r\n\tlet Y = [];\r\n\tfor (let i = 0; i < N; ++i) {\r\n\t\tlet row = data[i];\r\n\t\tlet x_i = [];\r\n\t\tlet y_i = row[row.length - 1];\r\n\t\tx_i.push(1.0);\r\n\t\tfor (let j = 0; j < row.length - 1; ++j) {\r\n\t\t\tx_i.push(row[j]);\r\n\t\t}\r\n\t\tX.push(x_i);\r\n\t\tY.push(y_i);\r\n\t}\r\n\r\n\tthis.theta = [];\r\n\tfor (let d = 0; d < this.dim; ++d) {\r\n\t\tthis.theta.push(0.0);\r\n\t}\r\n\r\n\tfor (let iter = 0; iter < this.iterations; ++iter) {\r\n\t\tlet theta_delta = this.grad(X, Y, this.theta);\r\n\t\tfor (let d = 0; d < this.dim; ++d) {\r\n\t\t\tthis.theta[d] = this.theta[d] - this.alpha * theta_delta[d];\r\n\t\t}\r\n\t}\r\n\r\n\tthis.threshold = this.computeThreshold(X, Y);\r\n\r\n\treturn {\r\n\t\ttheta: this.theta,\r\n\t\tthreshold: this.threshold,\r\n\t\tcost: this.cost(X, Y, this.theta),\r\n\t\tconfig: {\r\n\t\t\talpha: this.alpha,\r\n\t\t\tlambda: this.lambda,\r\n\t\t\titerations: this.iterations\r\n\t\t}\r\n\t};\r\n};\r\n\r\nLogisticRegression.prototype.computeThreshold = function(X, Y) {\r\n\tlet threshold = 1.0,\r\n\t\tN = X.length;\r\n\r\n\tfor (let i = 0; i < N; ++i) {\r\n\t\tlet prob = this.transform(X[i]);\r\n\t\tif (Y[i] === 1 && threshold > prob) {\r\n\t\t\tthreshold = prob;\r\n\t\t}\r\n\t}\r\n\r\n\treturn threshold;\r\n};\r\n\r\nLogisticRegression.prototype.grad = function(X, Y, theta) {\r\n\tlet N = X.length;\r\n\tlet Vx = [];\r\n\tfor (let d = 0; d < this.dim; ++d) {\r\n\t\tlet sum = 0.0;\r\n\t\tfor (let i = 0; i < N; ++i) {\r\n\t\t\tlet x_i = X[i];\r\n\t\t\tlet predicted = this.h(x_i, theta);\r\n\t\t\tsum += ((predicted - Y[i]) * x_i[d] + this.lambda * theta[d]) / N;\r\n\t\t}\r\n\t\tVx.push(sum);\r\n\t}\r\n\r\n\treturn Vx;\r\n};\r\n\r\nLogisticRegression.prototype.h = function(x_i, theta) {\r\n\tlet gx = 0.0;\r\n\tfor (let d = 0; d < this.dim; ++d) {\r\n\t\tgx += theta[d] * x_i[d];\r\n\t}\r\n\treturn 1.0 / (1.0 + Math.exp(-gx));\r\n};\r\n\r\nLogisticRegression.prototype.transform = function(x) {\r\n\tif (x[0].length) {\r\n\t\t// x is a matrix\r\n\t\tlet predicted_array = [];\r\n\t\tfor (let i = 0; i < x.length; ++i) {\r\n\t\t\tlet predicted = this.transform(x[i]);\r\n\t\t\tpredicted_array.push(predicted);\r\n\t\t}\r\n\t\treturn predicted_array;\r\n\t}\r\n\r\n\tlet x_i = [];\r\n\tx_i.push(1.0);\r\n\tfor (let j = 0; j < x.length; ++j) {\r\n\t\tx_i.push(x[j]);\r\n\t}\r\n\treturn this.h(x_i, this.theta);\r\n};\r\n\r\nLogisticRegression.prototype.predict = function(x) {\r\n\tlet gx = this.theta[0];\r\n\tfor (let d = 0; d < x.length; ++d) {\r\n\t\tgx += this.theta[d + 1] * x[d];\r\n\t}\r\n\treturn 1 / (1.0 + Math.exp(-gx));\r\n};\r\n\r\nLogisticRegression.prototype.predictClass = function(x) {\r\n\treturn this.predict(x) > 0.5 ? 1 : -1;\r\n};\r\n\r\nLogisticRegression.prototype.setOptions = function(configurations) {\r\n\tlet config_update = configurations || {};\r\n\tif (!config_update.alpha) {\r\n\t\tconfig_update.alpha = 0.001;\r\n\t}\r\n\tif (!config_update.iterations) {\r\n\t\tconfig_update.iterations = 100;\r\n\t}\r\n\tif (!config_update.lambda) {\r\n\t\tconfig_update.lambda = 0;\r\n\t}\r\n\tthis.alpha = config_update.alpha;\r\n\tthis.lambda = config_update.lambda;\r\n\tthis.iterations = config_update.iterations;\r\n};\r\n\r\nLogisticRegression.prototype.cost = function(X, Y, theta) {\r\n\tlet N = X.length;\r\n\tlet sum = 0;\r\n\tfor (let i = 0; i < N; ++i) {\r\n\t\tlet y_i = Y[i];\r\n\t\tlet x_i = X[i];\r\n\t\tsum += -(y_i * Math.log(this.h(x_i, theta)) + (1 - y_i) * Math.log(1 - this.h(x_i, theta))) / N;\r\n\t}\r\n\r\n\tfor (let d = 0; d < this.dim; ++d) {\r\n\t\tsum += this.lambda * theta[d] * theta[d] / (2.0 * N);\r\n\t}\r\n\treturn sum;\r\n};\r\n\r\n//_______________MultiClassLogistic______________-\r\n\r\nconst MultiClassLogistic = function(import_config) {\r\n\tlet config = import_config || {};\r\n\tif (!config.alpha) {\r\n\t\tconfig.alpha = 0.001;\r\n\t}\r\n\tif (!config.iterations) {\r\n\t\tconfig.iterations = 100;\r\n\t}\r\n\tif (!config.lambda) {\r\n\t\tconfig.lambda = 0;\r\n\t}\r\n\tthis.alpha = config.alpha;\r\n\tthis.lambda = config.lambda;\r\n\tthis.iterations = config.iterations;\r\n};\r\n\r\nMultiClassLogistic.prototype.fit = function(data, classes) {\r\n\tthis.dim = data[0].length;\r\n\tlet N = data.length;\r\n\r\n\tif (!classes) {\r\n\t\tclasses = [];\r\n\t\tfor (let i = 0; i < N; ++i) {\r\n\t\t\tlet found = false;\r\n\t\t\tlet label = data[i][this.dim - 1];\r\n\t\t\tfor (let j = 0; j < classes.length; ++j) {\r\n\t\t\t\tif (label === classes[j]) {\r\n\t\t\t\t\tfound = true;\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif (!found) {\r\n\t\t\t\tclasses.push(label);\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\tthis.classes = classes;\r\n\r\n\tthis.logistics = {};\r\n\tlet result = {};\r\n\tfor (let k = 0; k < this.classes.length; ++k) {\r\n\t\tlet c = this.classes[k];\r\n\t\tthis.logistics[c] = new jsr.LogisticRegression({\r\n\t\t\talpha: this.alpha,\r\n\t\t\tlambda: this.lambda,\r\n\t\t\titerations: this.iterations\r\n\t\t});\r\n\t\tlet data_c = [];\r\n\t\tfor (let i = 0; i < N; ++i) {\r\n\t\t\tlet row = [];\r\n\t\t\tfor (let j = 0; j < this.dim - 1; ++j) {\r\n\t\t\t\trow.push(data[i][j]);\r\n\t\t\t}\r\n\t\t\trow.push(data[i][this.dim - 1] === c ? 1 : 0);\r\n\t\t\tdata_c.push(row);\r\n\t\t}\r\n\t\tresult[c] = this.logistics[c].fit(data_c);\r\n\t}\r\n\treturn result;\r\n};\r\n\r\nMultiClassLogistic.prototype.transform = function(x) {\r\n\tif (x[0].length) {\r\n\t\t// x is a matrix\r\n\t\tlet predicted_array = [];\r\n\t\tfor (let i = 0; i < x.length; ++i) {\r\n\t\t\tlet predicted = this.transform(x[i]);\r\n\t\t\tpredicted_array.push(predicted);\r\n\t\t}\r\n\t\treturn predicted_array;\r\n\t}\r\n\r\n\tlet max_prob = 0.0;\r\n\tlet best_c = '';\r\n\tfor (let k = 0; k < this.classes.length; ++k) {\r\n\t\tlet c = this.classes[k];\r\n\t\tlet prob_c = this.logistics[c].transform(x);\r\n\t\tif (max_prob < prob_c) {\r\n\t\t\tmax_prob = prob_c;\r\n\t\t\tbest_c = c;\r\n\t\t}\r\n\t}\r\n\r\n\treturn best_c;\r\n};\r\n\n\n//# sourceURL=webpack:///./src/js/logreg/logreg.js?");

/***/ }),

/***/ "./src/js/nn/convnet.js":
/*!******************************!*\
  !*** ./src/js/nn/convnet.js ***!
  \******************************/
/*! exports provided: Vol, ConvLayer, FullyConnLayer, PoolLayer, InputLayer, SoftmaxLayer, RegressionLayer, SVMLayer, ReluLayer, SigmoidLayer, MaxoutLayer, TanhLayer, DropoutLayer, LocalResponseNormalizationLayer, Net, Trainer, MagicNet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Vol\", function() { return Vol; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConvLayer\", function() { return ConvLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FullyConnLayer\", function() { return FullyConnLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PoolLayer\", function() { return PoolLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"InputLayer\", function() { return InputLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SoftmaxLayer\", function() { return SoftmaxLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RegressionLayer\", function() { return RegressionLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SVMLayer\", function() { return SVMLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ReluLayer\", function() { return ReluLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SigmoidLayer\", function() { return SigmoidLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MaxoutLayer\", function() { return MaxoutLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TanhLayer\", function() { return TanhLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DropoutLayer\", function() { return DropoutLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LocalResponseNormalizationLayer\", function() { return LocalResponseNormalizationLayer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Net\", function() { return Net; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Trainer\", function() { return Trainer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MagicNet\", function() { return MagicNet; });\n\r\n// Random number utilities\r\nvar return_v = false;\r\nvar v_val = 0.0;\r\nvar gaussRandom = function() {\r\n    if(return_v) { \r\n        return_v = false;\r\n        return v_val; \r\n    }\r\n    var u = 2*Math.random()-1;\r\n    var v = 2*Math.random()-1;\r\n    var r = u*u + v*v;\r\n    if(r == 0 || r > 1) return gaussRandom();\r\n    var c = Math.sqrt(-2*Math.log(r)/r);\r\n    v_val = v*c; // cache this\r\n    return_v = true;\r\n    return u*c;\r\n}\r\n\r\nvar randf = function(a, b) { return Math.random()*(b-a)+a; }\r\nvar randi = function(a, b) { return Math.floor(Math.random()*(b-a)+a); }\r\nvar randn = function(mu, std){ return mu+gaussRandom()*std; }\r\n\r\n// Array utilities\r\nvar zeros = function(n) {\r\nif(typeof(n)==='undefined' || isNaN(n)) { return []; }\r\nif(typeof ArrayBuffer === 'undefined') {\r\n    // lacking browser support\r\n    var arr = new Array(n);\r\n    for(var i=0;i<n;i++) { arr[i]= 0; }\r\n    return arr;\r\n} else {\r\n    return new Float64Array(n);\r\n}\r\n}\r\n\r\nvar arrContains = function(arr, elt) {\r\nfor(var i=0,n=arr.length;i<n;i++) {\r\n    if(arr[i]===elt) return true;\r\n}\r\nreturn false;\r\n}\r\n\r\nvar arrUnique = function(arr) {\r\nvar b = [];\r\nfor(var i=0,n=arr.length;i<n;i++) {\r\n    if(!arrContains(b, arr[i])) {\r\n    b.push(arr[i]);\r\n    }\r\n}\r\nreturn b;\r\n}\r\n\r\n// return max and min of a given non-empty array.\r\nvar maxmin = function(w) {\r\nif(w.length === 0) { return {}; } // ... ;s\r\nvar maxv = w[0];\r\nvar minv = w[0];\r\nvar maxi = 0;\r\nvar mini = 0;\r\nvar n = w.length;\r\nfor(var i=1;i<n;i++) {\r\n    if(w[i] > maxv) { maxv = w[i]; maxi = i; } \r\n    if(w[i] < minv) { minv = w[i]; mini = i; } \r\n}\r\nreturn {maxi: maxi, maxv: maxv, mini: mini, minv: minv, dv:maxv-minv};\r\n}\r\n\r\n// create random permutation of numbers, in range [0...n-1]\r\nvar randperm = function(n) {\r\nvar i = n,\r\n    j = 0,\r\n    temp;\r\nvar array = [];\r\nfor(var q=0;q<n;q++)array[q]=q;\r\nwhile (i--) {\r\n    j = Math.floor(Math.random() * (i+1));\r\n    temp = array[i];\r\n    array[i] = array[j];\r\n    array[j] = temp;\r\n}\r\nreturn array;\r\n}\r\n\r\n// sample from list lst according to probabilities in list probs\r\n// the two lists are of same size, and probs adds up to 1\r\nvar weightedSample = function(lst, probs) {\r\nvar p = randf(0, 1.0);\r\nvar cumprob = 0.0;\r\nfor(var k=0,n=lst.length;k<n;k++) {\r\n    cumprob += probs[k];\r\n    if(p < cumprob) { return lst[k]; }\r\n}\r\n}\r\n\r\n// syntactic sugar function for getting default parameter values\r\nvar getopt = function(opt, field_name, default_value) {\r\nif(typeof field_name === 'string') {\r\n    // case of single string\r\n    return (typeof opt[field_name] !== 'undefined') ? opt[field_name] : default_value;\r\n} else {\r\n    // assume we are given a list of string instead\r\n    var ret = default_value;\r\n    for(var i=0;i<field_name.length;i++) {\r\n    var f = field_name[i];\r\n    if (typeof opt[f] !== 'undefined') {\r\n        ret = opt[f]; // overwrite return value\r\n    }\r\n    }\r\n    return ret;\r\n}\r\n}\r\n\r\nfunction assert(condition, message) {\r\n    if (!condition) {\r\n        message = message || \"Assertion failed\";\r\n        if (typeof Error !== \"undefined\") {\r\n        throw new Error(message);\r\n        }\r\n        throw message; // Fallback\r\n    }\r\n}\r\n  \r\n\r\n// Vol is the basic building block of all data in a net.\r\n// it is essentially just a 3D volume of numbers, with a\r\n// width (sx), height (sy), and depth (depth).\r\n// it is used to hold data for all filters, all volumes,\r\n// all weights, and also stores all gradients w.r.t. \r\n// the data. c is optionally a value to initialize the volume\r\n// with. If c is missing, fills the Vol with random numbers.\r\nconst Vol = function(sx, sy, depth, c) {\r\n    // this is how you check if a variable is an array. Oh, Javascript :)\r\n    if(Object.prototype.toString.call(sx) === '[object Array]') {\r\n        // we were given a list in sx, assume 1D volume and fill it up\r\n        this.sx = 1;\r\n        this.sy = 1;\r\n        this.depth = sx.length;\r\n        // we have to do the following copy because we want to use\r\n        // fast typed arrays, not an ordinary javascript array\r\n        this.w = zeros(this.depth);\r\n        this.dw = zeros(this.depth);\r\n        for(var i=0;i<this.depth;i++) {\r\n        this.w[i] = sx[i];\r\n        }\r\n    } else {\r\n        // we were given dimensions of the vol\r\n        this.sx = sx;\r\n        this.sy = sy;\r\n        this.depth = depth;\r\n        var n = sx*sy*depth;\r\n        this.w = zeros(n);\r\n        this.dw = zeros(n);\r\n        if(typeof c === 'undefined') {\r\n            // weight normalization is done to equalize the output\r\n            // variance of every neuron, otherwise neurons with a lot\r\n            // of incoming connections have outputs of larger variance\r\n            var scale = Math.sqrt(1.0/(sx*sy*depth));\r\n            for(var i=0;i<n;i++) { \r\n                this.w[i] = randn(0.0, scale);\r\n            }\r\n        } else {\r\n            for(var i=0;i<n;i++) { \r\n              this.w[i] = c;\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\nVol.prototype = {\r\n  get: function(x, y, d) { \r\n    var ix=((this.sx * y)+x)*this.depth+d;\r\n    return this.w[ix];\r\n  },\r\n  set: function(x, y, d, v) { \r\n    var ix=((this.sx * y)+x)*this.depth+d;\r\n    this.w[ix] = v; \r\n  },\r\n  add: function(x, y, d, v) { \r\n    var ix=((this.sx * y)+x)*this.depth+d;\r\n    this.w[ix] += v; \r\n  },\r\n  get_grad: function(x, y, d) { \r\n    var ix = ((this.sx * y)+x)*this.depth+d;\r\n    return this.dw[ix]; \r\n  },\r\n  set_grad: function(x, y, d, v) { \r\n    var ix = ((this.sx * y)+x)*this.depth+d;\r\n    this.dw[ix] = v; \r\n  },\r\n  add_grad: function(x, y, d, v) { \r\n    var ix = ((this.sx * y)+x)*this.depth+d;\r\n    this.dw[ix] += v; \r\n  },\r\n  cloneAndZero: function() { return new Vol(this.sx, this.sy, this.depth, 0.0)},\r\n  clone: function() {\r\n    var V = new Vol(this.sx, this.sy, this.depth, 0.0);\r\n    var n = this.w.length;\r\n    for(var i=0;i<n;i++) { V.w[i] = this.w[i]; }\r\n    return V;\r\n  },\r\n  addFrom: function(V) { for(var k=0;k<this.w.length;k++) { this.w[k] += V.w[k]; }},\r\n  addFromScaled: function(V, a) { for(var k=0;k<this.w.length;k++) { this.w[k] += a*V.w[k]; }},\r\n  setConst: function(a) { for(var k=0;k<this.w.length;k++) { this.w[k] = a; }},\r\n\r\n  toJSON: function() {\r\n    // todo: we may want to only save d most significant digits to save space\r\n    var json = {}\r\n    json.sx = this.sx; \r\n    json.sy = this.sy;\r\n    json.depth = this.depth;\r\n    json.w = this.w;\r\n    return json;\r\n    // we wont back up gradients to save space\r\n  },\r\n  fromJSON: function(json) {\r\n    this.sx = json.sx;\r\n    this.sy = json.sy;\r\n    this.depth = json.depth;\r\n\r\n    var n = this.sx*this.sy*this.depth;\r\n    this.w = zeros(n);\r\n    this.dw = zeros(n);\r\n    // copy over the elements.\r\n    for(var i=0;i<n;i++) {\r\n      this.w[i] = json.w[i];\r\n    }\r\n  }\r\n}\r\n\r\n\r\n// Volume utilities\r\n// intended for use with data augmentation\r\n// crop is the size of output\r\n// dx,dy are offset wrt incoming volume, of the shift\r\n// fliplr is boolean on whether we also want to flip left<->right\r\nvar augment = function(V, crop, dx, dy, fliplr) {\r\n  // note assumes square outputs of size crop x crop\r\n  if(typeof(fliplr)==='undefined') var fliplr = false;\r\n  if(typeof(dx)==='undefined') var dx = randi(0, V.sx - crop);\r\n  if(typeof(dy)==='undefined') var dy = randi(0, V.sy - crop);\r\n  \r\n  // randomly sample a crop in the input volume\r\n  var W;\r\n  if(crop !== V.sx || dx!==0 || dy!==0) {\r\n    W = new Vol(crop, crop, V.depth, 0.0);\r\n    for(var x=0;x<crop;x++) {\r\n      for(var y=0;y<crop;y++) {\r\n        if(x+dx<0 || x+dx>=V.sx || y+dy<0 || y+dy>=V.sy) continue; // oob\r\n        for(var d=0;d<V.depth;d++) {\r\n          W.set(x,y,d,V.get(x+dx,y+dy,d)); // copy data over\r\n        }\r\n      }\r\n    }\r\n  } else {\r\n    W = V;\r\n  }\r\n\r\n  if(fliplr) {\r\n    // flip volume horziontally\r\n    var W2 = W.cloneAndZero();\r\n    for(var x=0;x<W.sx;x++) {\r\n      for(var y=0;y<W.sy;y++) {\r\n        for(var d=0;d<W.depth;d++) {\r\n          W2.set(x,y,d,W.get(W.sx - x - 1,y,d)); // copy data over\r\n        }\r\n      }\r\n    }\r\n    W = W2; //swap\r\n  }\r\n  return W;\r\n}\r\n\r\n// img is a DOM element that contains a loaded image\r\n// returns a Vol of size (W, H, 4). 4 is for RGBA\r\nvar img_to_vol = function(img, convert_grayscale) {\r\n\r\n  if(typeof(convert_grayscale)==='undefined') var convert_grayscale = false;\r\n\r\n  var canvas = document.createElement('canvas');\r\n  canvas.width = img.width;\r\n  canvas.height = img.height;\r\n  var ctx = canvas.getContext(\"2d\");\r\n\r\n  // due to a Firefox bug\r\n  try {\r\n    ctx.drawImage(img, 0, 0);\r\n  } catch (e) {\r\n    if (e.name === \"NS_ERROR_NOT_AVAILABLE\") {\r\n      // sometimes happens, lets just abort\r\n      return false;\r\n    } else {\r\n      throw e;\r\n    }\r\n  }\r\n\r\n  try {\r\n    var img_data = ctx.getImageData(0, 0, canvas.width, canvas.height);\r\n  } catch (e) {\r\n    if(e.name === 'IndexSizeError') {\r\n      return false; // not sure what causes this sometimes but okay abort\r\n    } else {\r\n      throw e;\r\n    }\r\n  }\r\n\r\n  // prepare the input: get pixels and normalize them\r\n  var p = img_data.data;\r\n  var W = img.width;\r\n  var H = img.height;\r\n  var pv = []\r\n  for(var i=0;i<p.length;i++) {\r\n    pv.push(p[i]/255.0-0.5); // normalize image pixels to [-0.5, 0.5]\r\n  }\r\n  var x = new Vol(W, H, 4, 0.0); //input volume (image)\r\n  x.w = pv;\r\n\r\n  if(convert_grayscale) {\r\n    // flatten into depth=1 array\r\n    var x1 = new Vol(W, H, 1, 0.0);\r\n    for(var i=0;i<W;i++) {\r\n      for(var j=0;j<H;j++) {\r\n        x1.set(i,j,0,x.get(i,j,0));\r\n      }\r\n    }\r\n    x = x1;\r\n  }\r\n\r\n  return x;\r\n}\r\n\r\n// This file contains all layers that do dot products with input,\r\n// but usually in a different connectivity pattern and weight sharing\r\n// schemes: \r\n// - FullyConn is fully connected dot products \r\n// - ConvLayer does convolutions (so weight sharing spatially)\r\n// putting them together in one file because they are very similar\r\nconst ConvLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // required\r\n  this.out_depth = opt.filters;\r\n  this.sx = opt.sx; // filter size. Should be odd if possible, it's cleaner.\r\n  this.in_depth = opt.in_depth;\r\n  this.in_sx = opt.in_sx;\r\n  this.in_sy = opt.in_sy;\r\n  \r\n  // optional\r\n  this.sy = typeof opt.sy !== 'undefined' ? opt.sy : this.sx;\r\n  this.stride = typeof opt.stride !== 'undefined' ? opt.stride : 1; // stride at which we apply filters to input volume\r\n  this.pad = typeof opt.pad !== 'undefined' ? opt.pad : 0; // amount of 0 padding to add around borders of input volume\r\n  this.l1_decay_mul = typeof opt.l1_decay_mul !== 'undefined' ? opt.l1_decay_mul : 0.0;\r\n  this.l2_decay_mul = typeof opt.l2_decay_mul !== 'undefined' ? opt.l2_decay_mul : 1.0;\r\n\r\n  // computed\r\n  // note we are doing floor, so if the strided convolution of the filter doesnt fit into the input\r\n  // volume exactly, the output volume will be trimmed and not contain the (incomplete) computed\r\n  // final application.\r\n  this.out_sx = Math.floor((this.in_sx + this.pad * 2 - this.sx) / this.stride + 1);\r\n  this.out_sy = Math.floor((this.in_sy + this.pad * 2 - this.sy) / this.stride + 1);\r\n  this.layer_type = 'conv';\r\n\r\n  // initializations\r\n  var bias = typeof opt.bias_pref !== 'undefined' ? opt.bias_pref : 0.0;\r\n  this.filters = [];\r\n  for(var i=0;i<this.out_depth;i++) { this.filters.push(new Vol(this.sx, this.sy, this.in_depth)); }\r\n  this.biases = new Vol(1, 1, this.out_depth, bias);\r\n}\r\n\r\nConvLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    // optimized code by @mdda that achieves 2x speedup over previous version\r\n\r\n    this.in_act = V;\r\n    var A = new Vol(this.out_sx |0, this.out_sy |0, this.out_depth |0, 0.0);\r\n    \r\n    var V_sx = V.sx |0;\r\n    var V_sy = V.sy |0;\r\n    var xy_stride = this.stride |0;\r\n\r\n    for(var d=0;d<this.out_depth;d++) {\r\n      var f = this.filters[d];\r\n      var x = -this.pad |0;\r\n      var y = -this.pad |0;\r\n      for(var ay=0; ay<this.out_sy; y+=xy_stride,ay++) {  // xy_stride\r\n        x = -this.pad |0;\r\n        for(var ax=0; ax<this.out_sx; x+=xy_stride,ax++) {  // xy_stride\r\n\r\n          // convolve centered at this particular location\r\n          var a = 0.0;\r\n          for(var fy=0;fy<f.sy;fy++) {\r\n            var oy = y+fy; // coordinates in the original input array coordinates\r\n            for(var fx=0;fx<f.sx;fx++) {\r\n              var ox = x+fx;\r\n              if(oy>=0 && oy<V_sy && ox>=0 && ox<V_sx) {\r\n                for(var fd=0;fd<f.depth;fd++) {\r\n                  // avoid function call overhead (x2) for efficiency, compromise modularity :(\r\n                  a += f.w[((f.sx * fy)+fx)*f.depth+fd] * V.w[((V_sx * oy)+ox)*V.depth+fd];\r\n                }\r\n              }\r\n            }\r\n          }\r\n          a += this.biases.w[d];\r\n          A.set(ax, ay, d, a);\r\n        }\r\n      }\r\n    }\r\n    this.out_act = A;\r\n    return this.out_act;\r\n  },\r\n  backward: function() {\r\n\r\n    var V = this.in_act;\r\n    V.dw = zeros(V.w.length); // zero out gradient wrt bottom data, we're about to fill it\r\n\r\n    var V_sx = V.sx |0;\r\n    var V_sy = V.sy |0;\r\n    var xy_stride = this.stride |0;\r\n\r\n    for(var d=0;d<this.out_depth;d++) {\r\n      var f = this.filters[d];\r\n      var x = -this.pad |0;\r\n      var y = -this.pad |0;\r\n      for(var ay=0; ay<this.out_sy; y+=xy_stride,ay++) {  // xy_stride\r\n        x = -this.pad |0;\r\n        for(var ax=0; ax<this.out_sx; x+=xy_stride,ax++) {  // xy_stride\r\n\r\n          // convolve centered at this particular location\r\n          var chain_grad = this.out_act.get_grad(ax,ay,d); // gradient from above, from chain rule\r\n          for(var fy=0;fy<f.sy;fy++) {\r\n            var oy = y+fy; // coordinates in the original input array coordinates\r\n            for(var fx=0;fx<f.sx;fx++) {\r\n              var ox = x+fx;\r\n              if(oy>=0 && oy<V_sy && ox>=0 && ox<V_sx) {\r\n                for(var fd=0;fd<f.depth;fd++) {\r\n                  // avoid function call overhead (x2) for efficiency, compromise modularity :(\r\n                  var ix1 = ((V_sx * oy)+ox)*V.depth+fd;\r\n                  var ix2 = ((f.sx * fy)+fx)*f.depth+fd;\r\n                  f.dw[ix2] += V.w[ix1]*chain_grad;\r\n                  V.dw[ix1] += f.w[ix2]*chain_grad;\r\n                }\r\n              }\r\n            }\r\n          }\r\n          this.biases.dw[d] += chain_grad;\r\n        }\r\n      }\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    var response = [];\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      response.push({params: this.filters[i].w, grads: this.filters[i].dw, l2_decay_mul: this.l2_decay_mul, l1_decay_mul: this.l1_decay_mul});\r\n    }\r\n    response.push({params: this.biases.w, grads: this.biases.dw, l1_decay_mul: 0.0, l2_decay_mul: 0.0});\r\n    return response;\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.sx = this.sx; // filter size in x, y dims\r\n    json.sy = this.sy;\r\n    json.stride = this.stride;\r\n    json.in_depth = this.in_depth;\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.l1_decay_mul = this.l1_decay_mul;\r\n    json.l2_decay_mul = this.l2_decay_mul;\r\n    json.pad = this.pad;\r\n    json.filters = [];\r\n    for(var i=0;i<this.filters.length;i++) {\r\n      json.filters.push(this.filters[i].toJSON());\r\n    }\r\n    json.biases = this.biases.toJSON();\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.sx = json.sx; // filter size in x, y dims\r\n    this.sy = json.sy;\r\n    this.stride = json.stride;\r\n    this.in_depth = json.in_depth; // depth of input volume\r\n    this.filters = [];\r\n    this.l1_decay_mul = typeof json.l1_decay_mul !== 'undefined' ? json.l1_decay_mul : 1.0;\r\n    this.l2_decay_mul = typeof json.l2_decay_mul !== 'undefined' ? json.l2_decay_mul : 1.0;\r\n    this.pad = typeof json.pad !== 'undefined' ? json.pad : 0;\r\n    for(var i=0;i<json.filters.length;i++) {\r\n      var v = new Vol(0,0,0,0);\r\n      v.fromJSON(json.filters[i]);\r\n      this.filters.push(v);\r\n    }\r\n    this.biases = new Vol(0,0,0,0);\r\n    this.biases.fromJSON(json.biases);\r\n  }\r\n}\r\n\r\nconst FullyConnLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // required\r\n  // ok fine we will allow 'filters' as the word as well\r\n  this.out_depth = typeof opt.num_neurons !== 'undefined' ? opt.num_neurons : opt.filters;\r\n\r\n  // optional \r\n  this.l1_decay_mul = typeof opt.l1_decay_mul !== 'undefined' ? opt.l1_decay_mul : 0.0;\r\n  this.l2_decay_mul = typeof opt.l2_decay_mul !== 'undefined' ? opt.l2_decay_mul : 1.0;\r\n\r\n  // computed\r\n  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\r\n  this.out_sx = 1;\r\n  this.out_sy = 1;\r\n  this.layer_type = 'fc';\r\n\r\n  // initializations\r\n  var bias = typeof opt.bias_pref !== 'undefined' ? opt.bias_pref : 0.0;\r\n  this.filters = [];\r\n  for(var i=0;i<this.out_depth ;i++) { this.filters.push(new Vol(1, 1, this.num_inputs)); }\r\n  this.biases = new Vol(1, 1, this.out_depth, bias);\r\n};\r\n\r\nFullyConnLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    var A = new Vol(1, 1, this.out_depth, 0.0);\r\n    var Vw = V.w;\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      var a = 0.0;\r\n      var wi = this.filters[i].w;\r\n      for(var d=0;d<this.num_inputs;d++) {\r\n        a += Vw[d] * wi[d]; // for efficiency use Vols directly for now\r\n      }\r\n      a += this.biases.w[i];\r\n      A.w[i] = a;\r\n    }\r\n    this.out_act = A;\r\n    return this.out_act;\r\n  },\r\n  getFormula: function(input) {\r\n    let f;\r\n    let output = [];\r\n    for(let i=0;i<this.out_depth;i++) {\r\n      let wi = this.filters[i].w;\r\n      f = \"\";\r\n      for(let j=0;j<this.num_inputs;j++) {\r\n        if(j!==0 && wi[j]>0) f += \"+\";\r\n        f += wi[j].toPrecision(4)+\"*\"+input[j];\r\n      }\r\n      if(this.biases.w[i]>0) f += \"+\";\r\n      f += this.biases.w[i].toPrecision(4);\r\n      output.push(f);\r\n    }\r\n    return output;\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act;\r\n    V.dw =  zeros(V.w.length); // zero out the gradient in input Vol\r\n    \r\n    // compute gradient wrt weights and data\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      var tfi = this.filters[i];\r\n      var chain_grad = this.out_act.dw[i];\r\n      for(var d=0;d<this.num_inputs;d++) {\r\n        V.dw[d] += tfi.w[d]*chain_grad; // grad wrt input data\r\n        tfi.dw[d] += V.w[d]*chain_grad; // grad wrt params\r\n      }\r\n      this.biases.dw[i] += chain_grad;\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    var response = [];\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      response.push({params: this.filters[i].w, grads: this.filters[i].dw, l1_decay_mul: this.l1_decay_mul, l2_decay_mul: this.l2_decay_mul});\r\n    }\r\n    response.push({params: this.biases.w, grads: this.biases.dw, l1_decay_mul: 0.0, l2_decay_mul: 0.0});\r\n    return response;\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.num_inputs = this.num_inputs;\r\n    json.l1_decay_mul = this.l1_decay_mul;\r\n    json.l2_decay_mul = this.l2_decay_mul;\r\n    json.filters = [];\r\n    for(var i=0;i<this.filters.length;i++) {\r\n      json.filters.push(this.filters[i].toJSON());\r\n    }\r\n    json.biases = this.biases.toJSON();\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.num_inputs = json.num_inputs;\r\n    this.l1_decay_mul = typeof json.l1_decay_mul !== 'undefined' ? json.l1_decay_mul : 1.0;\r\n    this.l2_decay_mul = typeof json.l2_decay_mul !== 'undefined' ? json.l2_decay_mul : 1.0;\r\n    this.filters = [];\r\n    for(var i=0;i<json.filters.length;i++) {\r\n      var v = new Vol(0,0,0,0);\r\n      v.fromJSON(json.filters[i]);\r\n      this.filters.push(v);\r\n    }\r\n    this.biases = new Vol(0,0,0,0);\r\n    this.biases.fromJSON(json.biases);\r\n  }\r\n}\r\n\r\n  \r\nconst PoolLayer = function(opt) {\r\n\r\n  var opt = opt || {};\r\n\r\n  // required\r\n  this.sx = opt.sx; // filter size\r\n  this.in_depth = opt.in_depth;\r\n  this.in_sx = opt.in_sx;\r\n  this.in_sy = opt.in_sy;\r\n\r\n  // optional\r\n  this.sy = typeof opt.sy !== 'undefined' ? opt.sy : this.sx;\r\n  this.stride = typeof opt.stride !== 'undefined' ? opt.stride : 2;\r\n  this.pad = typeof opt.pad !== 'undefined' ? opt.pad : 0; // amount of 0 padding to add around borders of input volume\r\n\r\n  // computed\r\n  this.out_depth = this.in_depth;\r\n  this.out_sx = Math.floor((this.in_sx + this.pad * 2 - this.sx) / this.stride + 1);\r\n  this.out_sy = Math.floor((this.in_sy + this.pad * 2 - this.sy) / this.stride + 1);\r\n  this.layer_type = 'pool';\r\n  // store switches for x,y coordinates for where the max comes from, for each output neuron\r\n  this.switchx =  zeros(this.out_sx*this.out_sy*this.out_depth);\r\n  this.switchy =  zeros(this.out_sx*this.out_sy*this.out_depth);\r\n}\r\n\r\nPoolLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n\r\n    var A = new Vol(this.out_sx, this.out_sy, this.out_depth, 0.0);\r\n    \r\n    var n=0; // a counter for switches\r\n    for(var d=0;d<this.out_depth;d++) {\r\n      var x = -this.pad;\r\n      var y = -this.pad;\r\n      for(var ax=0; ax<this.out_sx; x+=this.stride,ax++) {\r\n        y = -this.pad;\r\n        for(var ay=0; ay<this.out_sy; y+=this.stride,ay++) {\r\n\r\n          // convolve centered at this particular location\r\n          var a = -99999; // hopefully small enough ;\\\r\n          var winx=-1,winy=-1;\r\n          for(var fx=0;fx<this.sx;fx++) {\r\n            for(var fy=0;fy<this.sy;fy++) {\r\n              var oy = y+fy;\r\n              var ox = x+fx;\r\n              if(oy>=0 && oy<V.sy && ox>=0 && ox<V.sx) {\r\n                var v = V.get(ox, oy, d);\r\n                // perform max pooling and store pointers to where\r\n                // the max came from. This will speed up backprop \r\n                // and can help make nice visualizations in future\r\n                if(v > a) { a = v; winx=ox; winy=oy;}\r\n              }\r\n            }\r\n          }\r\n          this.switchx[n] = winx;\r\n          this.switchy[n] = winy;\r\n          n++;\r\n          A.set(ax, ay, d, a);\r\n        }\r\n      }\r\n    }\r\n    this.out_act = A;\r\n    return this.out_act;\r\n  },\r\n  backward: function() { \r\n    // pooling layers have no parameters, so simply compute \r\n    // gradient wrt data here\r\n    var V = this.in_act;\r\n    V.dw =  zeros(V.w.length); // zero out gradient wrt data\r\n    var A = this.out_act; // computed in forward pass \r\n\r\n    var n = 0;\r\n    for(var d=0;d<this.out_depth;d++) {\r\n      var x = -this.pad;\r\n      var y = -this.pad;\r\n      for(var ax=0; ax<this.out_sx; x+=this.stride,ax++) {\r\n        y = -this.pad;\r\n        for(var ay=0; ay<this.out_sy; y+=this.stride,ay++) {\r\n\r\n          var chain_grad = this.out_act.get_grad(ax,ay,d);\r\n          V.add_grad(this.switchx[n], this.switchy[n], d, chain_grad);\r\n          n++;\r\n\r\n        }\r\n      }\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.sx = this.sx;\r\n    json.sy = this.sy;\r\n    json.stride = this.stride;\r\n    json.in_depth = this.in_depth;\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.pad = this.pad;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.sx = json.sx;\r\n    this.sy = json.sy;\r\n    this.stride = json.stride;\r\n    this.in_depth = json.in_depth;\r\n    this.pad = typeof json.pad !== 'undefined' ? json.pad : 0; // backwards compatibility\r\n    this.switchx =  zeros(this.out_sx*this.out_sy*this.out_depth); // need to re-init these appropriately\r\n    this.switchy =  zeros(this.out_sx*this.out_sy*this.out_depth);\r\n  }\r\n}\r\n\r\n\r\nconst InputLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // required: depth\r\n  this.out_depth = getopt(opt, ['out_depth', 'depth'], 0);\r\n\r\n  // optional: default these dimensions to 1\r\n  this.out_sx = getopt(opt, ['out_sx', 'sx', 'width'], 1);\r\n  this.out_sy = getopt(opt, ['out_sy', 'sy', 'height'], 1);\r\n  \r\n  // computed\r\n  this.layer_type = 'input';\r\n}\r\nInputLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    this.out_act = V;\r\n    return this.out_act; // simply identity function for now\r\n  },\r\n  backward: function() { },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n  }\r\n}\r\n\r\n  \r\n// Layers that implement a loss. Currently these are the layers that \r\n// can initiate a backward() pass. In future we probably want a more \r\n// flexible system that can accomodate multiple losses to do multi-task\r\n// learning, and stuff like that. But for now, one of the layers in this\r\n// file must be the final layer in a Net.\r\n\r\n// This is a classifier, with N discrete classes from 0 to N-1\r\n// it gets a stream of N incoming numbers and computes the softmax\r\n// function (exponentiate and normalize to sum to 1 as probabilities should)\r\nconst SoftmaxLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\r\n  this.out_depth = this.num_inputs;\r\n  this.out_sx = 1;\r\n  this.out_sy = 1;\r\n  this.layer_type = 'softmax';\r\n}\r\n\r\nSoftmaxLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n\r\n    var A = new Vol(1, 1, this.out_depth, 0.0);\r\n\r\n    // compute max activation\r\n    var as = V.w;\r\n    var amax = V.w[0];\r\n    for(var i=1;i<this.out_depth;i++) {\r\n      if(as[i] > amax) amax = as[i];\r\n    }\r\n\r\n    // compute exponentials (carefully to not blow up)\r\n    var es =  zeros(this.out_depth);\r\n    var esum = 0.0;\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      var e = Math.exp(as[i] - amax);\r\n      esum += e;\r\n      es[i] = e;\r\n    }\r\n\r\n    // normalize and output to sum to one\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      es[i] /= esum;\r\n      A.w[i] = es[i];\r\n    }\r\n\r\n    this.es = es; // save these for backprop\r\n    this.out_act = A;\r\n    return this.out_act;\r\n  },\r\n  backward: function(y) {\r\n\r\n    // compute and accumulate gradient wrt weights and bias of this layer\r\n    var x = this.in_act;\r\n    x.dw =  zeros(x.w.length); // zero out the gradient of input Vol\r\n\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      var indicator = i === y ? 1.0 : 0.0;\r\n      var mul = -(indicator - this.es[i]);\r\n      x.dw[i] = mul;\r\n    }\r\n\r\n    // loss is the class negative log likelihood\r\n    return -Math.log(this.es[y]);\r\n  },\r\n  getParamsAndGrads: function() { \r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.num_inputs = this.num_inputs;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.num_inputs = json.num_inputs;\r\n  }\r\n}\r\n\r\n// implements an L2 regression cost layer,\r\n// so penalizes \\sum_i(||x_i - y_i||^2), where x is its input\r\n// and y is the user-provided array of \"correct\" values.\r\nconst RegressionLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\r\n  this.out_depth = this.num_inputs;\r\n  this.out_sx = 1;\r\n  this.out_sy = 1;\r\n  this.layer_type = 'regression';\r\n}\r\n\r\nRegressionLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    this.out_act = V;\r\n    return V; // identity function\r\n  },\r\n  // y is a list here of size num_inputs\r\n  // or it can be a number if only one value is regressed\r\n  // or it can be a struct {dim: i, val: x} where we only want to \r\n  // regress on dimension i and asking it to have value x\r\n  backward: function(y) { \r\n\r\n    // compute and accumulate gradient wrt weights and bias of this layer\r\n    var x = this.in_act;\r\n    x.dw =  zeros(x.w.length); // zero out the gradient of input Vol\r\n    var loss = 0.0;\r\n    if(y instanceof Array || y instanceof Float64Array) {\r\n      for(var i=0;i<this.out_depth;i++) {\r\n        var dy = x.w[i] - y[i];\r\n        x.dw[i] = dy;\r\n        loss += 0.5*dy*dy;\r\n      }\r\n    } else if(typeof y === 'number') {\r\n      // lets hope that only one number is being regressed\r\n      var dy = x.w[0] - y;\r\n      x.dw[0] = dy;\r\n      loss += 0.5*dy*dy;\r\n    } else {\r\n      // assume it is a struct with entries .dim and .val\r\n      // and we pass gradient only along dimension dim to be equal to val\r\n      var i = y.dim;\r\n      var yi = y.val;\r\n      var dy = x.w[i] - yi;\r\n      x.dw[i] = dy;\r\n      loss += 0.5*dy*dy;\r\n    }\r\n    return loss;\r\n  },\r\n  getParamsAndGrads: function() { \r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.num_inputs = this.num_inputs;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.num_inputs = json.num_inputs;\r\n  }\r\n}\r\n\r\nconst SVMLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\r\n  this.out_depth = this.num_inputs;\r\n  this.out_sx = 1;\r\n  this.out_sy = 1;\r\n  this.layer_type = 'svm';\r\n}\r\n\r\nSVMLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    this.out_act = V; // nothing to do, output raw scores\r\n    return V;\r\n  },\r\n  backward: function(y) {\r\n\r\n    // compute and accumulate gradient wrt weights and bias of this layer\r\n    var x = this.in_act;\r\n    x.dw =  zeros(x.w.length); // zero out the gradient of input Vol\r\n\r\n    // we're using structured loss here, which means that the score\r\n    // of the ground truth should be higher than the score of any other \r\n    // class, by a margin\r\n    var yscore = x.w[y]; // score of ground truth\r\n    var margin = 1.0;\r\n    var loss = 0.0;\r\n    for(var i=0;i<this.out_depth;i++) {\r\n      if(y === i) { continue; }\r\n      var ydiff = -yscore + x.w[i] + margin;\r\n      if(ydiff > 0) {\r\n        // violating dimension, apply loss\r\n        x.dw[i] += 1;\r\n        x.dw[y] -= 1;\r\n        loss += ydiff;\r\n      }\r\n    }\r\n\r\n    return loss;\r\n  },\r\n  getParamsAndGrads: function() { \r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.num_inputs = this.num_inputs;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type;\r\n    this.num_inputs = json.num_inputs;\r\n  }\r\n}\r\n\r\n  \r\n// Implements ReLU nonlinearity elementwise\r\n// x -> max(0, x)\r\n// the output is in [0, inf)\r\nconst ReluLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = opt.in_depth;\r\n  this.layer_type = 'relu';\r\n}\r\nReluLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    var V2 = V.clone();\r\n    var N = V.w.length;\r\n    var V2w = V2.w;\r\n    for(var i=0;i<N;i++) { \r\n      if(V2w[i] < 0) V2w[i] = 0; // threshold at 0\r\n    }\r\n    this.out_act = V2;\r\n    return this.out_act;\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act; // we need to set dw of this\r\n    var V2 = this.out_act;\r\n    var N = V.w.length;\r\n    V.dw =  zeros(N); // zero out gradient wrt data\r\n    for(var i=0;i<N;i++) {\r\n      if(V2.w[i] <= 0) V.dw[i] = 0; // threshold\r\n      else V.dw[i] = V2.dw[i];\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n  }\r\n}\r\n\r\n// Implements Sigmoid nnonlinearity elementwise\r\n// x -> 1/(1+e^(-x))\r\n// so the output is between 0 and 1.\r\nconst SigmoidLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = opt.in_depth;\r\n  this.layer_type = 'sigmoid';\r\n}\r\nSigmoidLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    var V2 = V.cloneAndZero();\r\n    var N = V.w.length;\r\n    var V2w = V2.w;\r\n    var Vw = V.w;\r\n    for(var i=0;i<N;i++) { \r\n      V2w[i] = 1.0/(1.0+Math.exp(-Vw[i]));\r\n    }\r\n    this.out_act = V2;\r\n    return this.out_act;\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act; // we need to set dw of this\r\n    var V2 = this.out_act;\r\n    var N = V.w.length;\r\n    V.dw =  zeros(N); // zero out gradient wrt data\r\n    for(var i=0;i<N;i++) {\r\n      var v2wi = V2.w[i];\r\n      V.dw[i] =  v2wi * (1.0 - v2wi) * V2.dw[i];\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n  }\r\n}\r\n\r\n// Implements Maxout nnonlinearity that computes\r\n// x -> max(x)\r\n// where x is a vector of size group_size. Ideally of course,\r\n// the input size should be exactly divisible by group_size\r\nconst MaxoutLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // required\r\n  this.group_size = typeof opt.group_size !== 'undefined' ? opt.group_size : 2;\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = Math.floor(opt.in_depth / this.group_size);\r\n  this.layer_type = 'maxout';\r\n\r\n  this.switches =  zeros(this.out_sx*this.out_sy*this.out_depth); // useful for backprop\r\n}\r\nMaxoutLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    var N = this.out_depth; \r\n    var V2 = new Vol(this.out_sx, this.out_sy, this.out_depth, 0.0);\r\n\r\n    // optimization branch. If we're operating on 1D arrays we dont have\r\n    // to worry about keeping track of x,y,d coordinates inside\r\n    // input volumes. In convnets we do :(\r\n    if(this.out_sx === 1 && this.out_sy === 1) {\r\n      for(var i=0;i<N;i++) {\r\n        var ix = i * this.group_size; // base index offset\r\n        var a = V.w[ix];\r\n        var ai = 0;\r\n        for(var j=1;j<this.group_size;j++) {\r\n          var a2 = V.w[ix+j];\r\n          if(a2 > a) {\r\n            a = a2;\r\n            ai = j;\r\n          }\r\n        }\r\n        V2.w[i] = a;\r\n        this.switches[i] = ix + ai;\r\n      }\r\n    } else {\r\n      var n=0; // counter for switches\r\n      for(var x=0;x<V.sx;x++) {\r\n        for(var y=0;y<V.sy;y++) {\r\n          for(var i=0;i<N;i++) {\r\n            var ix = i * this.group_size;\r\n            var a = V.get(x, y, ix);\r\n            var ai = 0;\r\n            for(var j=1;j<this.group_size;j++) {\r\n              var a2 = V.get(x, y, ix+j);\r\n              if(a2 > a) {\r\n                a = a2;\r\n                ai = j;\r\n              }\r\n            }\r\n            V2.set(x,y,i,a);\r\n            this.switches[n] = ix + ai;\r\n            n++;\r\n          }\r\n        }\r\n      }\r\n\r\n    }\r\n    this.out_act = V2;\r\n    return this.out_act;\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act; // we need to set dw of this\r\n    var V2 = this.out_act;\r\n    var N = this.out_depth;\r\n    V.dw =  zeros(V.w.length); // zero out gradient wrt data\r\n\r\n    // pass the gradient through the appropriate switch\r\n    if(this.out_sx === 1 && this.out_sy === 1) {\r\n      for(var i=0;i<N;i++) {\r\n        var chain_grad = V2.dw[i];\r\n        V.dw[this.switches[i]] = chain_grad;\r\n      }\r\n    } else {\r\n      // bleh okay, lets do this the hard way\r\n      var n=0; // counter for switches\r\n      for(var x=0;x<V2.sx;x++) {\r\n        for(var y=0;y<V2.sy;y++) {\r\n          for(var i=0;i<N;i++) {\r\n            var chain_grad = V2.get_grad(x,y,i);\r\n            V.set_grad(x,y,this.switches[n],chain_grad);\r\n            n++;\r\n          }\r\n        }\r\n      }\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.group_size = this.group_size;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n    this.group_size = json.group_size;\r\n    this.switches =  zeros(this.group_size);\r\n  }\r\n}\r\n\r\n// a helper function, since tanh is not yet part of ECMAScript. Will be in v6.\r\nfunction tanh(x) {\r\n  var y = Math.exp(2 * x);\r\n  return (y - 1) / (y + 1);\r\n}\r\n// Implements Tanh nnonlinearity elementwise\r\n// x -> tanh(x) \r\n// so the output is between -1 and 1.\r\nconst TanhLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = opt.in_depth;\r\n  this.layer_type = 'tanh';\r\n}\r\nTanhLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    var V2 = V.cloneAndZero();\r\n    var N = V.w.length;\r\n    for(var i=0;i<N;i++) { \r\n      V2.w[i] = tanh(V.w[i]);\r\n    }\r\n    this.out_act = V2;\r\n    return this.out_act;\r\n  },\r\n  getFormula: function(input){\r\n    for(let i=0;i<input.length;i++) {\r\n      input[i]=\"tanh(\"+input[i]+\")\";\r\n    }\r\n    return input;\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act; // we need to set dw of this\r\n    var V2 = this.out_act;\r\n    var N = V.w.length;\r\n    V.dw =  zeros(N); // zero out gradient wrt data\r\n    for(var i=0;i<N;i++) {\r\n      var v2wi = V2.w[i];\r\n      V.dw[i] = (1.0 - v2wi * v2wi) * V2.dw[i];\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n  }\r\n}\r\n\r\n\r\n// An inefficient dropout layer\r\n// Note this is not most efficient implementation since the layer before\r\n// computed all these activations and now we're just going to drop them :(\r\n// same goes for backward pass. Also, if we wanted to be efficient at test time\r\n// we could equivalently be clever and upscale during train and copy pointers during test\r\n// todo: make more efficient.\r\nconst DropoutLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = opt.in_depth;\r\n  this.layer_type = 'dropout';\r\n  this.drop_prob = typeof opt.drop_prob !== 'undefined' ? opt.drop_prob : 0.5;\r\n  this.dropped =  zeros(this.out_sx*this.out_sy*this.out_depth);\r\n}\r\nDropoutLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n    if(typeof(is_training)==='undefined') { is_training = false; } // default is prediction mode\r\n    var V2 = V.clone();\r\n    var N = V.w.length;\r\n    if(is_training) {\r\n      // do dropout\r\n      for(var i=0;i<N;i++) {\r\n        if(Math.random()<this.drop_prob) { V2.w[i]=0; this.dropped[i] = true; } // drop!\r\n        else {this.dropped[i] = false;}\r\n      }\r\n    } else {\r\n      // scale the activations during prediction\r\n      for(var i=0;i<N;i++) { V2.w[i]*=this.drop_prob; }\r\n    }\r\n    this.out_act = V2;\r\n    return this.out_act; // dummy identity function for now\r\n  },\r\n  backward: function() {\r\n    var V = this.in_act; // we need to set dw of this\r\n    var chain_grad = this.out_act;\r\n    var N = V.w.length;\r\n    V.dw =  zeros(N); // zero out gradient wrt data\r\n    for(var i=0;i<N;i++) {\r\n      if(!(this.dropped[i])) { \r\n        V.dw[i] = chain_grad.dw[i]; // copy over the gradient\r\n      }\r\n    }\r\n  },\r\n  getParamsAndGrads: function() {\r\n    return [];\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.out_depth = this.out_depth;\r\n    json.out_sx = this.out_sx;\r\n    json.out_sy = this.out_sy;\r\n    json.layer_type = this.layer_type;\r\n    json.drop_prob = this.drop_prob;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.out_depth = json.out_depth;\r\n    this.out_sx = json.out_sx;\r\n    this.out_sy = json.out_sy;\r\n    this.layer_type = json.layer_type; \r\n    this.drop_prob = json.drop_prob;\r\n  }\r\n}\r\n  \r\n  \r\n// a bit experimental layer for now. I think it works but I'm not 100%\r\n// the gradient check is a bit funky. I'll look into this a bit later.\r\n// Local Response Normalization in window, along depths of volumes\r\nconst LocalResponseNormalizationLayer = function(opt) {\r\n  var opt = opt || {};\r\n\r\n  // required\r\n  this.k = opt.k;\r\n  this.n = opt.n;\r\n  this.alpha = opt.alpha;\r\n  this.beta = opt.beta;\r\n\r\n  // computed\r\n  this.out_sx = opt.in_sx;\r\n  this.out_sy = opt.in_sy;\r\n  this.out_depth = opt.in_depth;\r\n  this.layer_type = 'lrn';\r\n\r\n  // checks\r\n  if(this.n%2 === 0) { console.log('WARNING n should be odd for LRN layer'); }\r\n}\r\nLocalResponseNormalizationLayer.prototype = {\r\n  forward: function(V, is_training) {\r\n    this.in_act = V;\r\n\r\n    var A = V.cloneAndZero();\r\n    this.S_cache_ = V.cloneAndZero();\r\n    var n2 = Math.floor(this.n/2);\r\n    for(var x=0;x<V.sx;x++) {\r\n      for(var y=0;y<V.sy;y++) {\r\n        for(var i=0;i<V.depth;i++) {\r\n\r\n          var ai = V.get(x,y,i);\r\n\r\n          // normalize in a window of size n\r\n          var den = 0.0;\r\n          for(var j=Math.max(0,i-n2);j<=Math.min(i+n2,V.depth-1);j++) {\r\n            var aa = V.get(x,y,j);\r\n            den += aa*aa;\r\n          }\r\n          den *= this.alpha / this.n;\r\n          den += this.k;\r\n          this.S_cache_.set(x,y,i,den); // will be useful for backprop\r\n          den = Math.pow(den, this.beta);\r\n          A.set(x,y,i,ai/den);\r\n        }\r\n      }\r\n    }\r\n\r\n    this.out_act = A;\r\n    return this.out_act; // dummy identity function for now\r\n  },\r\n  backward: function() { \r\n    // evaluate gradient wrt data\r\n    var V = this.in_act; // we need to set dw of this\r\n    V.dw =  zeros(V.w.length); // zero out gradient wrt data\r\n    var A = this.out_act; // computed in forward pass \r\n\r\n    var n2 = Math.floor(this.n/2);\r\n    for(var x=0;x<V.sx;x++) {\r\n      for(var y=0;y<V.sy;y++) {\r\n        for(var i=0;i<V.depth;i++) {\r\n\r\n          var chain_grad = this.out_act.get_grad(x,y,i);\r\n          var S = this.S_cache_.get(x,y,i);\r\n          var SB = Math.pow(S, this.beta);\r\n          var SB2 = SB*SB;\r\n\r\n          // normalize in a window of size n\r\n          for(var j=Math.max(0,i-n2);j<=Math.min(i+n2,V.depth-1);j++) {              \r\n            var aj = V.get(x,y,j); \r\n            var g = -aj*this.beta*Math.pow(S,this.beta-1)*this.alpha/this.n*2*aj;\r\n            if(j===i) g+= SB;\r\n            g /= SB2;\r\n            g *= chain_grad;\r\n            V.add_grad(x,y,j,g);\r\n          }\r\n\r\n        }\r\n      }\r\n    }\r\n  },\r\n  getParamsAndGrads: function() { return []; },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.k = this.k;\r\n    json.n = this.n;\r\n    json.alpha = this.alpha; // normalize by size\r\n    json.beta = this.beta;\r\n    json.out_sx = this.out_sx; \r\n    json.out_sy = this.out_sy;\r\n    json.out_depth = this.out_depth;\r\n    json.layer_type = this.layer_type;\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.k = json.k;\r\n    this.n = json.n;\r\n    this.alpha = json.alpha; // normalize by size\r\n    this.beta = json.beta;\r\n    this.out_sx = json.out_sx; \r\n    this.out_sy = json.out_sy;\r\n    this.out_depth = json.out_depth;\r\n    this.layer_type = json.layer_type;\r\n  }\r\n}\r\n\r\n\r\n// Net manages a set of layers\r\n// For now constraints: Simple linear order of layers, first layer input last layer a cost layer\r\nconst Net = function(options) {\r\n  this.layers = [];\r\n}\r\n\r\nNet.prototype = {\r\n  \r\n  // takes a list of layer definitions and creates the network layer objects\r\n  makeLayers: function(defs) {\r\n\r\n    // few checks\r\n    assert(defs.length >= 2, 'Error! At least one input layer and one loss layer are required.');\r\n    assert(defs[0].type === 'input', 'Error! First layer must be the input layer, to declare size of inputs');\r\n\r\n    // desugar layer_defs for adding activation, dropout layers etc\r\n    var desugar = function() {\r\n      var new_defs = [];\r\n      for(var i=0;i<defs.length;i++) {\r\n        var def = defs[i];\r\n        \r\n        if(def.type==='softmax' || def.type==='svm') {\r\n          // add an fc layer here, there is no reason the user should\r\n          // have to worry about this and we almost always want to\r\n          new_defs.push({type:'fc', num_neurons: def.num_classes});\r\n        }\r\n\r\n        if(def.type==='regression') {\r\n          // add an fc layer here, there is no reason the user should\r\n          // have to worry about this and we almost always want to\r\n          new_defs.push({type:'fc', num_neurons: def.num_neurons});\r\n        }\r\n\r\n        if((def.type==='fc' || def.type==='conv') \r\n            && typeof(def.bias_pref) === 'undefined'){\r\n          def.bias_pref = 0.0;\r\n          if(typeof def.activation !== 'undefined' && def.activation === 'relu') {\r\n            def.bias_pref = 0.1; // relus like a bit of positive bias to get gradients early\r\n            // otherwise it's technically possible that a relu unit will never turn on (by chance)\r\n            // and will never get any gradient and never contribute any computation. Dead relu.\r\n          }\r\n        }\r\n\r\n        new_defs.push(def);\r\n\r\n        if(typeof def.activation !== 'undefined') {\r\n          if(def.activation==='relu') { new_defs.push({type:'relu'}); }\r\n          else if (def.activation==='sigmoid') { new_defs.push({type:'sigmoid'}); }\r\n          else if (def.activation==='tanh') { new_defs.push({type:'tanh'}); }\r\n          else if (def.activation==='maxout') {\r\n            // create maxout activation, and pass along group size, if provided\r\n            var gs = def.group_size !== 'undefined' ? def.group_size : 2;\r\n            new_defs.push({type:'maxout', group_size:gs});\r\n          }\r\n          else { console.log('ERROR unsupported activation ' + def.activation); }\r\n        }\r\n        if(typeof def.drop_prob !== 'undefined' && def.type !== 'dropout') {\r\n          new_defs.push({type:'dropout', drop_prob: def.drop_prob});\r\n        }\r\n\r\n      }\r\n      return new_defs;\r\n    }\r\n    defs = desugar(defs);\r\n\r\n    // create the layers\r\n    this.layers = [];\r\n    for(var i=0;i<defs.length;i++) {\r\n      var def = defs[i];\r\n      if(i>0) {\r\n        var prev = this.layers[i-1];\r\n        def.in_sx = prev.out_sx;\r\n        def.in_sy = prev.out_sy;\r\n        def.in_depth = prev.out_depth;\r\n      }\r\n\r\n      switch(def.type) {\r\n        case 'fc': this.layers.push(new  FullyConnLayer(def)); break;\r\n        case 'lrn': this.layers.push(new  LocalResponseNormalizationLayer(def)); break;\r\n        case 'dropout': this.layers.push(new  DropoutLayer(def)); break;\r\n        case 'input': this.layers.push(new  InputLayer(def)); break;\r\n        case 'softmax': this.layers.push(new  SoftmaxLayer(def)); break;\r\n        case 'regression': this.layers.push(new  RegressionLayer(def)); break;\r\n        case 'conv': this.layers.push(new  ConvLayer(def)); break;\r\n        case 'pool': this.layers.push(new  PoolLayer(def)); break;\r\n        case 'relu': this.layers.push(new  ReluLayer(def)); break;\r\n        case 'sigmoid': this.layers.push(new  SigmoidLayer(def)); break;\r\n        case 'tanh': this.layers.push(new  TanhLayer(def)); break;\r\n        case 'maxout': this.layers.push(new  MaxoutLayer(def)); break;\r\n        case 'svm': this.layers.push(new  SVMLayer(def)); break;\r\n        default: console.log('ERROR: UNRECOGNIZED LAYER TYPE: ' + def.type);\r\n      }\r\n    }\r\n  },\r\n\r\n  // forward prop the network. \r\n  // The trainer class passes is_training = true, but when this function is\r\n  // called from outside (not from the trainer), it defaults to prediction mode\r\n  forward: function(V, is_training) {\r\n    if(typeof(is_training) === 'undefined') is_training = false;\r\n    var act = this.layers[0].forward(V, is_training);\r\n    for(var i=1;i<this.layers.length;i++) {\r\n      act = this.layers[i].forward(act, is_training);\r\n    }\r\n    return act;\r\n  },\r\n\r\n  getFormula: function(input){\r\n    let formula = \"\";\r\n    let formule = input;\r\n\r\n    for(let i=1;i<this.layers.length;i++) { // per tutti gli strati che ci sono\r\n      if(this.layers[i].layer_type===\"fc\") { // quando c'è un full connected\r\n        formule = this.layers[i].getFormula(formule); // il numero di formule viene ridotto dal numero di input al numero di output\r\n      }\r\n      else if(this.layers[i].layer_type!==\"input\" && this.layers[i].layer_type!==\"softmax\" ){ //se non è uno strato di input, o quello softmax => applico la trasformazione\r\n        //layer della funzione tanh\r\n        formule = this.layers[i].getFormula(formule);\r\n      }\r\n    }\r\n\r\n    for(let i=0;i<formule.length;i++){\r\n      if(i===0)\r\n        formula+=formule[i];\r\n      else\r\n        formula+=\"-(\"+formule[i]+\")\";\r\n    }\r\n    console.info(\"formule\");\r\n    console.table(formule);\r\n    return formula;\r\n  },\r\n\r\n  getCostLoss: function(V, y) {\r\n    this.forward(V, false);\r\n    var N = this.layers.length;\r\n    var loss = this.layers[N-1].backward(y);\r\n    return loss;\r\n  },\r\n  \r\n  // backprop: compute gradients wrt all parameters\r\n  backward: function(y) {\r\n    var N = this.layers.length;\r\n    var loss = this.layers[N-1].backward(y); // last layer assumed to be loss layer\r\n    for(var i=N-2;i>=0;i--) { // first layer assumed input\r\n      this.layers[i].backward();\r\n    }\r\n    return loss;\r\n  },\r\n  getParamsAndGrads: function() {\r\n    // accumulate parameters and gradients for the entire network\r\n    var response = [];\r\n    for(var i=0;i<this.layers.length;i++) {\r\n      var layer_reponse = this.layers[i].getParamsAndGrads();\r\n      for(var j=0;j<layer_reponse.length;j++) {\r\n        response.push(layer_reponse[j]);\r\n      }\r\n    }\r\n    return response;\r\n  },\r\n  getPrediction: function() {\r\n    // this is a convenience function for returning the argmax\r\n    // prediction, assuming the last layer of the net is a softmax\r\n    var S = this.layers[this.layers.length-1];\r\n    assert(S.layer_type === 'softmax', 'getPrediction function assumes softmax as last layer of the net!');\r\n\r\n    var p = S.out_act.w;\r\n    var maxv = p[0];\r\n    var maxi = 0;\r\n    for(var i=1;i<p.length;i++) {\r\n      if(p[i] > maxv) { maxv = p[i]; maxi = i;}\r\n    }\r\n    return maxi; // return index of the class with highest class probability\r\n  },\r\n  toJSON: function() {\r\n    var json = {};\r\n    json.layers = [];\r\n    for(var i=0;i<this.layers.length;i++) {\r\n      json.layers.push(this.layers[i].toJSON());\r\n    }\r\n    return json;\r\n  },\r\n  fromJSON: function(json) {\r\n    this.layers = [];\r\n    for(var i=0;i<json.layers.length;i++) {\r\n      var Lj = json.layers[i]\r\n      var t = Lj.layer_type;\r\n      var L;\r\n      if(t==='input') { L = new  InputLayer(); }\r\n      if(t==='relu') { L = new  ReluLayer(); }\r\n      if(t==='sigmoid') { L = new  SigmoidLayer(); }\r\n      if(t==='tanh') { L = new  TanhLayer(); }\r\n      if(t==='dropout') { L = new  DropoutLayer(); }\r\n      if(t==='conv') { L = new  ConvLayer(); }\r\n      if(t==='pool') { L = new  PoolLayer(); }\r\n      if(t==='lrn') { L = new  LocalResponseNormalizationLayer(); }\r\n      if(t==='softmax') { L = new  SoftmaxLayer(); }\r\n      if(t==='regression') { L = new  RegressionLayer(); }\r\n      if(t==='fc') { L = new  FullyConnLayer(); }\r\n      if(t==='maxout') { L = new  MaxoutLayer(); }\r\n      if(t==='svm') { L = new  SVMLayer(); }\r\n      L.fromJSON(Lj);\r\n      this.layers.push(L);\r\n    }\r\n  }\r\n}\r\n\r\n\r\nconst Trainer = function(net, options) {\r\n\r\n  this.net = net;\r\n\r\n  var options = options || {};\r\n  this.learning_rate = typeof options.learning_rate !== 'undefined' ? options.learning_rate : 0.01;\r\n  this.l1_decay = typeof options.l1_decay !== 'undefined' ? options.l1_decay : 0.0;\r\n  this.l2_decay = typeof options.l2_decay !== 'undefined' ? options.l2_decay : 0.0;\r\n  this.batch_size = typeof options.batch_size !== 'undefined' ? options.batch_size : 1;\r\n  this.method = typeof options.method !== 'undefined' ? options.method : 'sgd'; // sgd/adagrad/adadelta/windowgrad/netsterov\r\n\r\n  this.momentum = typeof options.momentum !== 'undefined' ? options.momentum : 0.9;\r\n  this.ro = typeof options.ro !== 'undefined' ? options.ro : 0.95; // used in adadelta\r\n  this.eps = typeof options.eps !== 'undefined' ? options.eps : 1e-6; // used in adadelta\r\n\r\n  this.k = 0; // iteration counter\r\n  this.gsum = []; // last iteration gradients (used for momentum calculations)\r\n  this.xsum = []; // used in adadelta\r\n}\r\n\r\nTrainer.prototype = {\r\n  train: function(x, y) {\r\n\r\n    var start = new Date().getTime();\r\n    this.net.forward(x, true); // also set the flag that lets the net know we're just training\r\n    var end = new Date().getTime();\r\n    var fwd_time = end - start;\r\n\r\n    var start = new Date().getTime();\r\n    var cost_loss = this.net.backward(y);\r\n    var l2_decay_loss = 0.0;\r\n    var l1_decay_loss = 0.0;\r\n    var end = new Date().getTime();\r\n    var bwd_time = end - start;\r\n    \r\n    this.k++;\r\n    if(this.k % this.batch_size === 0) {\r\n\r\n      var pglist = this.net.getParamsAndGrads();\r\n\r\n      // initialize lists for accumulators. Will only be done once on first iteration\r\n      if(this.gsum.length === 0 && (this.method !== 'sgd' || this.momentum > 0.0)) {\r\n        // only vanilla sgd doesnt need either lists\r\n        // momentum needs gsum\r\n        // adagrad needs gsum\r\n        // adadelta needs gsum and xsum\r\n        for(var i=0;i<pglist.length;i++) {\r\n          this.gsum.push( zeros(pglist[i].params.length));\r\n          if(this.method === 'adadelta') {\r\n            this.xsum.push( zeros(pglist[i].params.length));\r\n          } else {\r\n            this.xsum.push([]); // conserve memory\r\n          }\r\n        }\r\n      }\r\n\r\n      // perform an update for all sets of weights\r\n      for(var i=0;i<pglist.length;i++) {\r\n        var pg = pglist[i]; // param, gradient, other options in future (custom learning rate etc)\r\n        var p = pg.params;\r\n        var g = pg.grads;\r\n\r\n        // learning rate for some parameters.\r\n        var l2_decay_mul = typeof pg.l2_decay_mul !== 'undefined' ? pg.l2_decay_mul : 1.0;\r\n        var l1_decay_mul = typeof pg.l1_decay_mul !== 'undefined' ? pg.l1_decay_mul : 1.0;\r\n        var l2_decay = this.l2_decay * l2_decay_mul;\r\n        var l1_decay = this.l1_decay * l1_decay_mul;\r\n\r\n        var plen = p.length;\r\n        for(var j=0;j<plen;j++) {\r\n          l2_decay_loss += l2_decay*p[j]*p[j]/2; // accumulate weight decay loss\r\n          l1_decay_loss += l1_decay*Math.abs(p[j]);\r\n          var l1grad = l1_decay * (p[j] > 0 ? 1 : -1);\r\n          var l2grad = l2_decay * (p[j]);\r\n\r\n          var gij = (l2grad + l1grad + g[j]) / this.batch_size; // raw batch gradient\r\n\r\n          var gsumi = this.gsum[i];\r\n          var xsumi = this.xsum[i];\r\n          if(this.method === 'adagrad') {\r\n            // adagrad update\r\n            gsumi[j] = gsumi[j] + gij * gij;\r\n            var dx = - this.learning_rate / Math.sqrt(gsumi[j] + this.eps) * gij;\r\n            p[j] += dx;\r\n          } else if(this.method === 'windowgrad') {\r\n            // this is adagrad but with a moving window weighted average\r\n            // so the gradient is not accumulated over the entire history of the run. \r\n            // it's also referred to as Idea #1 in Zeiler paper on Adadelta. Seems reasonable to me!\r\n            gsumi[j] = this.ro * gsumi[j] + (1-this.ro) * gij * gij;\r\n            var dx = - this.learning_rate / Math.sqrt(gsumi[j] + this.eps) * gij; // eps added for better conditioning\r\n            p[j] += dx;\r\n          } else if(this.method === 'adadelta') {\r\n            // assume adadelta if not sgd or adagrad\r\n            gsumi[j] = this.ro * gsumi[j] + (1-this.ro) * gij * gij;\r\n            var dx = - Math.sqrt((xsumi[j] + this.eps)/(gsumi[j] + this.eps)) * gij;\r\n            xsumi[j] = this.ro * xsumi[j] + (1-this.ro) * dx * dx; // yes, xsum lags behind gsum by 1.\r\n            p[j] += dx;\r\n          } else if(this.method === 'nesterov') {\r\n            var dx = gsumi[j];\r\n            gsumi[j] = gsumi[j] * this.momentum + this.learning_rate * gij;\r\n              dx = this.momentum * dx - (1.0 + this.momentum) * gsumi[j];\r\n              p[j] += dx;\r\n          } else {\r\n            // assume SGD\r\n            if(this.momentum > 0.0) {\r\n              // momentum update\r\n              var dx = this.momentum * gsumi[j] - this.learning_rate * gij; // step\r\n              gsumi[j] = dx; // back this up for next iteration of momentum\r\n              p[j] += dx; // apply corrected gradient\r\n            } else {\r\n              // vanilla sgd\r\n              p[j] +=  - this.learning_rate * gij;\r\n            }\r\n          }\r\n          g[j] = 0.0; // zero out gradient so that we can begin accumulating anew\r\n        }\r\n      }\r\n    }\r\n\r\n    // appending softmax_loss for backwards compatibility, but from now on we will always use cost_loss\r\n    // in future, TODO: have to completely redo the way loss is done around the network as currently \r\n    // loss is a bit of a hack. Ideally, user should specify arbitrary number of loss functions on any layer\r\n    // and it should all be computed correctly and automatically. \r\n    return {fwd_time: fwd_time, bwd_time: bwd_time, \r\n            l2_decay_loss: l2_decay_loss, l1_decay_loss: l1_decay_loss,\r\n            cost_loss: cost_loss, softmax_loss: cost_loss, \r\n            loss: cost_loss + l1_decay_loss + l2_decay_loss}\r\n  }\r\n}\r\n\r\n\r\n/*\r\nA MagicNet takes data: a list of convnetjs.Vol(), and labels\r\nwhich for now are assumed to be class indeces 0..K. MagicNet then:\r\n- creates data folds for cross-validation\r\n- samples candidate networks\r\n- evaluates candidate networks on all data folds\r\n- produces predictions by model-averaging the best networks\r\n*/\r\nconst MagicNet = function(data, labels, opt) {\r\n  var opt = opt || {};\r\n  if(typeof data === 'undefined') { data = []; }\r\n  if(typeof labels === 'undefined') { labels = []; }\r\n\r\n  // required inputs\r\n  this.data = data; // store these pointers to data\r\n  this.labels = labels;\r\n\r\n  // optional inputs\r\n  this.train_ratio = getopt(opt, 'train_ratio', 0.7);\r\n  this.num_folds = getopt(opt, 'num_folds', 10);\r\n  this.num_candidates = getopt(opt, 'num_candidates', 50); // we evaluate several in parallel\r\n  // how many epochs of data to train every network? for every fold?\r\n  // higher values mean higher accuracy in final results, but more expensive\r\n  this.num_epochs = getopt(opt, 'num_epochs', 50); \r\n  // number of best models to average during prediction. Usually higher = better\r\n  this.ensemble_size = getopt(opt, 'ensemble_size', 10);\r\n\r\n  // candidate parameters\r\n  this.batch_size_min = getopt(opt, 'batch_size_min', 10);\r\n  this.batch_size_max = getopt(opt, 'batch_size_max', 300);\r\n  this.l2_decay_min = getopt(opt, 'l2_decay_min', -4);\r\n  this.l2_decay_max = getopt(opt, 'l2_decay_max', 2);\r\n  this.learning_rate_min = getopt(opt, 'learning_rate_min', -4);\r\n  this.learning_rate_max = getopt(opt, 'learning_rate_max', 0);\r\n  this.momentum_min = getopt(opt, 'momentum_min', 0.9);\r\n  this.momentum_max = getopt(opt, 'momentum_max', 0.9);\r\n  this.neurons_min = getopt(opt, 'neurons_min', 5);\r\n  this.neurons_max = getopt(opt, 'neurons_max', 30);\r\n\r\n  // computed\r\n  this.folds = []; // data fold indices, gets filled by sampleFolds()\r\n  this.candidates = []; // candidate networks that are being currently evaluated\r\n  this.evaluated_candidates = []; // history of all candidates that were fully evaluated on all folds\r\n  this.unique_labels = arrUnique(labels);\r\n  this.iter = 0; // iteration counter, goes from 0 -> num_epochs * num_training_data\r\n  this.foldix = 0; // index of active fold\r\n\r\n  // callbacks\r\n  this.finish_fold_callback = null;\r\n  this.finish_batch_callback = null;\r\n\r\n  // initializations\r\n  if(this.data.length > 0) {\r\n    this.sampleFolds();\r\n    this.sampleCandidates();\r\n  }\r\n};\r\n\r\nMagicNet.prototype = {\r\n\r\n  // sets this.folds to a sampling of this.num_folds folds\r\n  sampleFolds: function() {\r\n    var N = this.data.length;\r\n    var num_train = Math.floor(this.train_ratio * N);\r\n    this.folds = []; // flush folds, if any\r\n    for(var i=0;i<this.num_folds;i++) {\r\n      var p = randperm(N);\r\n      this.folds.push({train_ix: p.slice(0, num_train), test_ix: p.slice(num_train, N)});\r\n    }\r\n  },\r\n\r\n  // returns a random candidate network\r\n  sampleCandidate: function() {\r\n    var input_depth = this.data[0].w.length;\r\n    var num_classes = this.unique_labels.length;\r\n\r\n    // sample network topology and hyperparameters\r\n    var layer_defs = [];\r\n    layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth: input_depth});\r\n    var nl = weightedSample([0,1,2,3], [0.2, 0.3, 0.3, 0.2]); // prefer nets with 1,2 hidden layers\r\n    for(var q=0;q<nl;q++) {\r\n      var ni = randi(this.neurons_min, this.neurons_max);\r\n      var act = ['tanh','maxout','relu'][randi(0,3)];\r\n      if(randf(0,1)<0.5) {\r\n        var dp = Math.random();\r\n        layer_defs.push({type:'fc', num_neurons: ni, activation: act, drop_prob: dp});\r\n      } else {\r\n        layer_defs.push({type:'fc', num_neurons: ni, activation: act});\r\n      }\r\n    }\r\n    layer_defs.push({type:'softmax', num_classes: num_classes});\r\n    var net = new Net();\r\n    net.makeLayers(layer_defs);\r\n\r\n    // sample training hyperparameters\r\n    var bs = randi(this.batch_size_min, this.batch_size_max); // batch size\r\n    var l2 = Math.pow(10, randf(this.l2_decay_min, this.l2_decay_max)); // l2 weight decay\r\n    var lr = Math.pow(10, randf(this.learning_rate_min, this.learning_rate_max)); // learning rate\r\n    var mom = randf(this.momentum_min, this.momentum_max); // momentum. Lets just use 0.9, works okay usually ;p\r\n    var tp = randf(0,1); // trainer type\r\n    var trainer_def;\r\n    if(tp<0.33) {\r\n      trainer_def = {method:'adadelta', batch_size:bs, l2_decay:l2};\r\n    } else if(tp<0.66) {\r\n      trainer_def = {method:'adagrad', learning_rate: lr, batch_size:bs, l2_decay:l2};\r\n    } else {\r\n      trainer_def = {method:'sgd', learning_rate: lr, momentum: mom, batch_size:bs, l2_decay:l2};\r\n    }\r\n    \r\n    var trainer = new Trainer(net, trainer_def);\r\n\r\n    var cand = {};\r\n    cand.acc = [];\r\n    cand.accv = 0; // this will maintained as sum(acc) for convenience\r\n    cand.layer_defs = layer_defs;\r\n    cand.trainer_def = trainer_def;\r\n    cand.net = net;\r\n    cand.trainer = trainer;\r\n    return cand;\r\n  },\r\n\r\n  // sets this.candidates with this.num_candidates candidate nets\r\n  sampleCandidates: function() {\r\n    this.candidates = []; // flush, if any\r\n    for(var i=0;i<this.num_candidates;i++) {\r\n      var cand = this.sampleCandidate();\r\n      this.candidates.push(cand);\r\n    }\r\n  },\r\n\r\n  step: function() {\r\n    \r\n    // run an example through current candidate\r\n    this.iter++;\r\n\r\n    // step all candidates on a random data point\r\n    var fold = this.folds[this.foldix]; // active fold\r\n    var dataix = fold.train_ix[randi(0, fold.train_ix.length)];\r\n    for(var k=0;k<this.candidates.length;k++) {\r\n      var x = this.data[dataix];\r\n      var l = this.labels[dataix];\r\n      this.candidates[k].trainer.train(x, l);\r\n    }\r\n\r\n    // process consequences: sample new folds, or candidates\r\n    var lastiter = this.num_epochs * fold.train_ix.length;\r\n    if(this.iter >= lastiter) {\r\n      // finished evaluation of this fold. Get final validation\r\n      // accuracies, record them, and go on to next fold.\r\n      var val_acc = this.evalValErrors();\r\n      for(var k=0;k<this.candidates.length;k++) {\r\n        var c = this.candidates[k];\r\n        c.acc.push(val_acc[k]);\r\n        c.accv += val_acc[k];\r\n      }\r\n      this.iter = 0; // reset step number\r\n      this.foldix++; // increment fold\r\n\r\n      if(this.finish_fold_callback !== null) {\r\n        this.finish_fold_callback();\r\n      }\r\n\r\n      if(this.foldix >= this.folds.length) {\r\n        // we finished all folds as well! Record these candidates\r\n        // and sample new ones to evaluate.\r\n        for(var k=0;k<this.candidates.length;k++) {\r\n          this.evaluated_candidates.push(this.candidates[k]);\r\n        }\r\n        // sort evaluated candidates according to accuracy achieved\r\n        this.evaluated_candidates.sort(function(a, b) { \r\n          return (a.accv / a.acc.length) \r\n                > (b.accv / b.acc.length) \r\n                ? -1 : 1;\r\n        });\r\n        // and clip only to the top few ones (lets place limit at 3*ensemble_size)\r\n        // otherwise there are concerns with keeping these all in memory \r\n        // if MagicNet is being evaluated for a very long time\r\n        if(this.evaluated_candidates.length > 3 * this.ensemble_size) {\r\n          this.evaluated_candidates = this.evaluated_candidates.slice(0, 3 * this.ensemble_size);\r\n        }\r\n        if(this.finish_batch_callback !== null) {\r\n          this.finish_batch_callback();\r\n        }\r\n        this.sampleCandidates(); // begin with new candidates\r\n        this.foldix = 0; // reset this\r\n      } else {\r\n        // we will go on to another fold. reset all candidates nets\r\n        for(var k=0;k<this.candidates.length;k++) {\r\n          var c = this.candidates[k];\r\n          var net = new Net();\r\n          net.makeLayers(c.layer_defs);\r\n          var trainer = new Trainer(net, c.trainer_def);\r\n          c.net = net;\r\n          c.trainer = trainer;\r\n        }\r\n      }\r\n    }\r\n  },\r\n\r\n  evalValErrors: function() {\r\n    // evaluate candidates on validation data and return performance of current networks\r\n    // as simple list\r\n    var vals = [];\r\n    var fold = this.folds[this.foldix]; // active fold\r\n    for(var k=0;k<this.candidates.length;k++) {\r\n      var net = this.candidates[k].net;\r\n      var v = 0.0;\r\n      for(var q=0;q<fold.test_ix.length;q++) {\r\n        var x = this.data[fold.test_ix[q]];\r\n        var l = this.labels[fold.test_ix[q]];\r\n        net.forward(x);\r\n        var yhat = net.getPrediction();\r\n        v += (yhat === l ? 1.0 : 0.0); // 0 1 loss\r\n      }\r\n      v /= fold.test_ix.length; // normalize\r\n      vals.push(v);\r\n    }\r\n    return vals;\r\n  },\r\n\r\n  // returns prediction scores for given test data point, as Vol\r\n  // uses an averaged prediction from the best ensemble_size models\r\n  // x is a Vol.\r\n  predict_soft: function(data) {\r\n    // forward prop the best networks\r\n    // and accumulate probabilities at last layer into a an output Vol\r\n\r\n    var eval_candidates = [];\r\n    var nv = 0;\r\n    if(this.evaluated_candidates.length === 0) {\r\n      // not sure what to do here, first batch of nets hasnt evaluated yet\r\n      // lets just predict with current candidates.\r\n      nv = this.candidates.length;\r\n      eval_candidates = this.candidates;\r\n    } else {\r\n      // forward prop the best networks from evaluated_candidates\r\n      nv = Math.min(this.ensemble_size, this.evaluated_candidates.length);\r\n      eval_candidates = this.evaluated_candidates\r\n    }\r\n\r\n    // forward nets of all candidates and average the predictions\r\n    var xout, n;\r\n    for(var j=0;j<nv;j++) {\r\n      var net = eval_candidates[j].net;\r\n      var x = net.forward(data);\r\n      if(j===0) { \r\n        xout = x; \r\n        n = x.w.length; \r\n      } else {\r\n        // add it on\r\n        for(var d=0;d<n;d++) {\r\n          xout.w[d] += x.w[d];\r\n        }\r\n      }\r\n    }\r\n    // produce average\r\n    for(var d=0;d<n;d++) {\r\n      xout.w[d] /= nv;\r\n    }\r\n    return xout;\r\n  },\r\n\r\n  predict: function(data) {\r\n    var xout = this.predict_soft(data);\r\n    if(xout.w.length !== 0) {\r\n      var stats = maxmin(xout.w);\r\n      var predicted_label = stats.maxi; \r\n    } else {\r\n      var predicted_label = -1; // error out\r\n    }\r\n    return predicted_label;\r\n\r\n  },\r\n\r\n  toJSON: function() {\r\n    // dump the top ensemble_size networks as a list\r\n    var nv = Math.min(this.ensemble_size, this.evaluated_candidates.length);\r\n    var json = {};\r\n    json.nets = [];\r\n    for(var i=0;i<nv;i++) {\r\n      json.nets.push(this.evaluated_candidates[i].net.toJSON());\r\n    }\r\n    return json;\r\n  },\r\n\r\n  fromJSON: function(json) {\r\n    this.ensemble_size = json.nets.length;\r\n    this.evaluated_candidates = [];\r\n    for(var i=0;i<this.ensemble_size;i++) {\r\n      var net = new Net();\r\n      net.fromJSON(json.nets[i]);\r\n      var dummy_candidate = {};\r\n      dummy_candidate.net = net;\r\n      this.evaluated_candidates.push(dummy_candidate);\r\n    }\r\n  },\r\n\r\n  // callback functions\r\n  // called when a fold is finished, while evaluating a batch\r\n  onFinishFold: function(f) { this.finish_fold_callback = f; },\r\n  // called when a batch of candidates has finished evaluating\r\n  onFinishBatch: function(f) { this.finish_batch_callback = f; }\r\n  \r\n};\n\n//# sourceURL=webpack:///./src/js/nn/convnet.js?");

/***/ }),

/***/ "./src/js/nn/nn.js":
/*!*************************!*\
  !*** ./src/js/nn/nn.js ***!
  \*************************/
/*! exports provided: NeuralNet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"NeuralNet\", function() { return NeuralNet; });\n/* harmony import */ var _convnet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./convnet */ \"./src/js/nn/convnet.js\");\n\r\nconst NeuralNet = function() {};\r\nNeuralNet.prototype = {\r\n\ttrain: function(data, labels, options) {\r\n\t\tlet layer_defs = [];\r\n\t\tlayer_defs.push({ type: 'input', out_sx: 1, out_sy: 1, out_depth: 2 });\r\n\t\tlayer_defs.push({ type: 'fc', num_neurons: 4, activation: 'tanh' });\r\n\t\tlayer_defs.push({ type: 'fc', num_neurons: 4, activation: 'tanh' });\r\n\t\tlayer_defs.push({ type: 'fc', num_neurons: 4, activation: 'tanh' });\r\n\t\tlayer_defs.push({ type: 'softmax', num_classes: 2 });\r\n\t\tthis.net = new _convnet__WEBPACK_IMPORTED_MODULE_0__[\"Net\"]();\r\n\t\tthis.net.makeLayers(layer_defs);\r\n\t\tlet trainer = new _convnet__WEBPACK_IMPORTED_MODULE_0__[\"Trainer\"](this.net, { learning_rate: 0.01, momentum: 0.1, batch_size: 10, l2_decay: 0.001 });\r\n\t\tlet x = new _convnet__WEBPACK_IMPORTED_MODULE_0__[\"Vol\"](1, 1, 2, 0.0);\r\n\t\tlet maxiter = options.iters || 1000;\r\n\t\tfor (let iters = 0; iters < maxiter; iters++) {\r\n\t\t\tfor (let i = 0; i < data.length; i++) {\r\n\t\t\t\tx.w = data[i];\r\n\t\t\t\tif (labels[i] === 1) trainer.train(x, 1);\r\n\t\t\t\telse trainer.train(x, 0);\r\n\t\t\t}\r\n\t\t}\r\n\t},\r\n\tpredict: function(point) {\r\n\t\tlet input = new _convnet__WEBPACK_IMPORTED_MODULE_0__[\"Vol\"](1, 1, 2, 0.0);\r\n\t\tinput.w = point;\r\n\t\tlet a = this.net.forward(input, false);\r\n\t\treturn (Math.tanh(a.w[1] - a.w[0]) + 1) / 2;\r\n\t\t// return a.w[0] > a.w[1] ? -1 : 1;\r\n\t},\r\n\tpredictClass: function(point) {\r\n\t\tlet input = new _convnet__WEBPACK_IMPORTED_MODULE_0__[\"Vol\"](1, 1, 2, 0.0);\r\n\t\tinput.w = point;\r\n\t\tlet a = this.net.forward(input, false);\r\n\t\treturn a.w[0] > a.w[1] ? -1 : 1;\r\n\t}\r\n};\r\n\n\n//# sourceURL=webpack:///./src/js/nn/nn.js?");

/***/ }),

/***/ "./src/js/randf/randf.js":
/*!*******************************!*\
  !*** ./src/js/randf/randf.js ***!
  \*******************************/
/*! exports provided: RandomForest */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RandomForest\", function() { return RandomForest; });\n// MIT License\r\n// Andrej Karpathy\r\n\r\nconst RandomForest = function() {};\r\n\r\nRandomForest.prototype = {\r\n\t/*\r\n    data is 2D array of size N x D of examples\r\n    labels is a 1D array of labels (only -1 or 1 for now). In future will support multiclass or maybe even regression\r\n    options.numTrees can be used to customize number of trees to train (default = 100)\r\n    options.maxDepth is the maximum depth of each tree in the forest (default = 4)\r\n    options.numTries is the number of random hypotheses generated at each node during training (default = 10)\r\n    options.trainFun is a function with signature \"function myWeakTrain(data, labels, ix, options)\". Here, ix is a list of\r\n                     indeces into data of the instances that should be payed attention to. Everything not in the list\r\n                     should be ignored. This is done for efficiency. The function should return a model where you store\r\n                     variables. (i.e. model = {}; model.myvar = 5;) This will be passed to testFun.\r\n    options.testFun is a function with signature \"funtion myWeakTest(inst, model)\" where inst is 1D array specifying an example,\r\n                     and model will be the same model that you return in options.trainFun. For example, model.myvar will be 5.\r\n                     see decisionStumpTrain() and decisionStumpTest() downstairs for example.\r\n    */\r\n\ttrain: function(data, labels, options) {\r\n\t\toptions = options || {};\r\n\t\tthis.numTrees = options.numTrees || 100;\r\n\r\n\t\t// initialize many trees and train them all independently\r\n\t\tthis.trees = new Array(this.numTrees);\r\n\t\tfor (let i = 0; i < this.numTrees; i++) {\r\n\t\t\tthis.trees[i] = new DecisionTree();\r\n\t\t\tthis.trees[i].train(data, labels, options);\r\n\t\t}\r\n\t},\r\n\r\n\t/*\r\n    inst is a 1D array of length D of an example.\r\n    returns the probability of label 1, i.e. a number in range [0, 1]\r\n    */\r\n\tpredict: function(point) {\r\n\t\t// have each tree predict and average out all votes\r\n\t\tlet dec = 0;\r\n\t\tfor (let i = 0; i < this.numTrees; i++) {\r\n\t\t\tdec += this.trees[i].predictOne(point);\r\n\t\t}\r\n\t\tdec /= this.numTrees;\r\n\t\treturn dec;\r\n\t},\r\n\r\n\tpredictClass: function(point) {\r\n\t\treturn this.predict(point) > 0.5 ? 1 : -1;\r\n\t}\r\n};\r\n\r\n// represents a single decision tree\r\nlet DecisionTree = function() {};\r\n\r\nDecisionTree.prototype = {\r\n\ttrain: function(data, labels, options) {\r\n\t\toptions = options || {};\r\n\t\tlet maxDepth = options.maxDepth || 4;\r\n\t\tlet weakType = options.type || 0;\r\n\r\n\t\tlet trainFun = decision2DStumpTrain;\r\n\t\tlet testFun = decision2DStumpTest;\r\n\r\n\t\tif (options.trainFun) trainFun = options.trainFun;\r\n\t\tif (options.testFun) testFun = options.testFun;\r\n\r\n\t\tif (weakType === 0) {\r\n\t\t\ttrainFun = decisionStumpTrain;\r\n\t\t\ttestFun = decisionStumpTest;\r\n\t\t}\r\n\t\tif (weakType === 1) {\r\n\t\t\ttrainFun = decision2DStumpTrain;\r\n\t\t\ttestFun = decision2DStumpTest;\r\n\t\t}\r\n\r\n\t\t// initialize various helper variables\r\n\t\tlet numInternals = Math.pow(2, maxDepth) - 1;\r\n\t\tlet numNodes = Math.pow(2, maxDepth + 1) - 1;\r\n\t\tlet ixs = new Array(numNodes);\r\n\t\tfor (let i = 1; i < ixs.length; i++) ixs[i] = [];\r\n\t\tixs[0] = new Array(labels.length);\r\n\t\tfor (let i = 0; i < labels.length; i++) ixs[0][i] = i; // root node starts out with all nodes as relevant\r\n\t\tlet models = new Array(numInternals);\r\n\r\n\t\t// train\r\n\t\tfor (let n = 0; n < numInternals; n++) {\r\n\t\t\t// few base cases\r\n\t\t\tlet ixhere = ixs[n];\r\n\t\t\tif (ixhere.length === 0) {\r\n\t\t\t\tcontinue;\r\n\t\t\t}\r\n\t\t\tif (ixhere.length === 1) {\r\n\t\t\t\tixs[n * 2 + 1] = [ ixhere[0] ];\r\n\t\t\t\tcontinue;\r\n\t\t\t} // arbitrary send it down left\r\n\r\n\t\t\t// learn a weak model on relevant data for this node\r\n\t\t\tlet model = trainFun(data, labels, ixhere);\r\n\t\t\tmodels[n] = model; // back it up model\r\n\r\n\t\t\t// split the data according to the learned model\r\n\t\t\tlet ixleft = [];\r\n\t\t\tlet ixright = [];\r\n\t\t\tfor (let i = 0; i < ixhere.length; i++) {\r\n\t\t\t\tlet label = testFun(data[ixhere[i]], model);\r\n\t\t\t\tif (label === 1) ixleft.push(ixhere[i]);\r\n\t\t\t\telse ixright.push(ixhere[i]);\r\n\t\t\t}\r\n\t\t\tixs[n * 2 + 1] = ixleft;\r\n\t\t\tixs[n * 2 + 2] = ixright;\r\n\t\t}\r\n\r\n\t\t// compute data distributions at the leafs\r\n\t\tlet leafPositives = new Array(numNodes);\r\n\t\tlet leafNegatives = new Array(numNodes);\r\n\t\tfor (let n = numInternals; n < numNodes; n++) {\r\n\t\t\tlet numones = 0;\r\n\t\t\tfor (let i = 0; i < ixs[n].length; i++) {\r\n\t\t\t\tif (labels[ixs[n][i]] === 1) numones += 1;\r\n\t\t\t}\r\n\t\t\tleafPositives[n] = numones;\r\n\t\t\tleafNegatives[n] = ixs[n].length - numones;\r\n\t\t}\r\n\r\n\t\t// back up important prediction variables for predicting later\r\n\t\tthis.models = models;\r\n\t\tthis.leafPositives = leafPositives;\r\n\t\tthis.leafNegatives = leafNegatives;\r\n\t\tthis.maxDepth = maxDepth;\r\n\t\tthis.trainFun = trainFun;\r\n\t\tthis.testFun = testFun;\r\n\t},\r\n\r\n\t// returns probability that example inst is 1.\r\n\tpredictOne: function(inst) {\r\n\t\tlet n = 0;\r\n\t\tfor (let i = 0; i < this.maxDepth; i++) {\r\n\t\t\tlet dir = this.testFun(inst, this.models[n]);\r\n\t\t\tif (dir === 1)\r\n\t\t\t\tn = n * 2 + 1; // descend left\r\n\t\t\telse n = n * 2 + 2; // descend right\r\n\t\t}\r\n\r\n\t\treturn (this.leafPositives[n] + 0.5) / (this.leafNegatives[n] + 1.0); // bayesian smoothing!\r\n\t}\r\n};\r\n\r\n// returns model\r\nfunction decisionStumpTrain(data, labels, ix, options) {\r\n\toptions = options || {};\r\n\tlet numtries = options.numTries || 10;\r\n\r\n\t// choose a dimension at random and pick a best split\r\n\tlet ri = randi(0, data[0].length);\r\n\tlet N = ix.length;\r\n\r\n\t// evaluate class entropy of incoming data\r\n\tlet H = entropy(labels, ix);\r\n\tlet bestGain = 0;\r\n\tlet bestThr = 0;\r\n\tfor (let i = 0; i < numtries; i++) {\r\n\t\t// pick a random splitting threshold\r\n\t\tlet ix1 = ix[randi(0, N)];\r\n\t\tlet ix2 = ix[randi(0, N)];\r\n\t\twhile (ix2 === ix1) ix2 = ix[randi(0, N)]; // enforce distinctness of ix2\r\n\r\n\t\tlet a = Math.random();\r\n\t\tlet thr = data[ix1][ri] * a + data[ix2][ri] * (1 - a);\r\n\r\n\t\t// measure information gain we'd get from split with thr\r\n\t\tlet l1 = 1,\r\n\t\t\tr1 = 1,\r\n\t\t\tlm1 = 1,\r\n\t\t\trm1 = 1; //counts for Left and label 1, right and label 1, left and minus 1, right and minus 1\r\n\t\tfor (let j = 0; j < ix.length; j++) {\r\n\t\t\tif (data[ix[j]][ri] < thr) {\r\n\t\t\t\tif (labels[ix[j]] === 1) l1++;\r\n\t\t\t\telse lm1++;\r\n\t\t\t} else {\r\n\t\t\t\tif (labels[ix[j]] === 1) r1++;\r\n\t\t\t\telse rm1++;\r\n\t\t\t}\r\n\t\t}\r\n\t\tlet t = l1 + lm1; // normalize the counts to obtain probability estimates\r\n\t\tl1 = l1 / t;\r\n\t\tlm1 = lm1 / t;\r\n\t\tt = r1 + rm1;\r\n\t\tr1 = r1 / t;\r\n\t\trm1 = rm1 / t;\r\n\r\n\t\tlet LH = -l1 * Math.log(l1) - lm1 * Math.log(lm1); // left and right entropy\r\n\t\tlet RH = -r1 * Math.log(r1) - rm1 * Math.log(rm1);\r\n\r\n\t\tlet informationGain = H - LH - RH;\r\n\t\t//console.log(\"Considering split %f, entropy %f -> %f, %f. Gain %f\", thr, H, LH, RH, informationGain);\r\n\t\tif (informationGain > bestGain || i === 0) {\r\n\t\t\tbestGain = informationGain;\r\n\t\t\tbestThr = thr;\r\n\t\t}\r\n\t}\r\n\treturn {\r\n\t\tthr: bestThr,\r\n\t\tri: ri\r\n\t};\r\n}\r\n\r\n// returns a decision for a single data instance\r\nfunction decisionStumpTest(inst, model) {\r\n\tif (!model) {\r\n\t\t// this is a leaf that never received any data...\r\n\t\treturn 1;\r\n\t}\r\n\treturn inst[model.ri] < model.thr ? 1 : -1;\r\n}\r\n\r\n// returns model. Code duplication with decisionStumpTrain :(\r\nfunction decision2DStumpTrain(data, labels, ix, options) {\r\n\toptions = options || {};\r\n\tlet numtries = options.numTries || 10;\r\n\r\n\t// choose a dimension at random and pick a best split\r\n\tlet N = ix.length;\r\n\r\n\tlet ri1 = 0;\r\n\tlet ri2 = 1;\r\n\tif (data[0].length > 2) {\r\n\t\t// more than 2D data. Pick 2 random dimensions\r\n\t\tri1 = randi(0, data[0].length);\r\n\t\tri2 = randi(0, data[0].length);\r\n\t\twhile (ri2 === ri1) ri2 = randi(0, data[0].length); // must be distinct!\r\n\t}\r\n\r\n\t// evaluate class entropy of incoming data\r\n\tlet H = entropy(labels, ix);\r\n\tlet bestGain = 0;\r\n\tlet bestw1, bestw2, bestthr;\r\n\tlet dots = new Array(ix.length);\r\n\tfor (let i = 0; i < numtries; i++) {\r\n\t\t// pick random line parameters\r\n\t\tlet alpha = randf(0, 2 * Math.PI);\r\n\t\tlet w1 = Math.cos(alpha);\r\n\t\tlet w2 = Math.sin(alpha);\r\n\r\n\t\t// project data on this line and get the dot products\r\n\t\tfor (let j = 0; j < ix.length; j++) {\r\n\t\t\tdots[j] = w1 * data[ix[j]][ri1] + w2 * data[ix[j]][ri2];\r\n\t\t}\r\n\r\n\t\t// we are in a tricky situation because data dot product distribution\r\n\t\t// can be skewed. So we don't want to select just randomly between\r\n\t\t// min and max. But we also don't want to sort as that is too expensive\r\n\t\t// let's pick two random points and make the threshold be somewhere between them.\r\n\t\t// for skewed datasets, the selected points will with relatively high likelihood\r\n\t\t// be in the high-desnity regions, so the thresholds will make sense\r\n\t\tlet ix1 = ix[randi(0, N)];\r\n\t\tlet ix2 = ix[randi(0, N)];\r\n\t\twhile (ix2 === ix1) ix2 = ix[randi(0, N)]; // enforce distinctness of ix2\r\n\t\tlet a = Math.random();\r\n\t\tlet dotthr = dots[ix1] * a + dots[ix2] * (1 - a);\r\n\r\n\t\t// measure information gain we'd get from split with thr\r\n\t\tlet l1 = 1,\r\n\t\t\tr1 = 1,\r\n\t\t\tlm1 = 1,\r\n\t\t\trm1 = 1; //counts for Left and label 1, right and label 1, left and minus 1, right and minus 1\r\n\t\tfor (let j = 0; j < ix.length; j++) {\r\n\t\t\tif (dots[j] < dotthr) {\r\n\t\t\t\tif (labels[ix[j]] === 1) l1++;\r\n\t\t\t\telse lm1++;\r\n\t\t\t} else {\r\n\t\t\t\tif (labels[ix[j]] === 1) r1++;\r\n\t\t\t\telse rm1++;\r\n\t\t\t}\r\n\t\t}\r\n\t\tlet t = l1 + lm1;\r\n\t\tl1 = l1 / t;\r\n\t\tlm1 = lm1 / t;\r\n\t\tt = r1 + rm1;\r\n\t\tr1 = r1 / t;\r\n\t\trm1 = rm1 / t;\r\n\r\n\t\tlet LH = -l1 * Math.log(l1) - lm1 * Math.log(lm1); // left and right entropy\r\n\t\tlet RH = -r1 * Math.log(r1) - rm1 * Math.log(rm1);\r\n\r\n\t\tlet informationGain = H - LH - RH;\r\n\t\t//console.log(\"Considering split %f, entropy %f -> %f, %f. Gain %f\", thr, H, LH, RH, informationGain);\r\n\t\tif (informationGain > bestGain || i === 0) {\r\n\t\t\tbestGain = informationGain;\r\n\t\t\tbestw1 = w1;\r\n\t\t\tbestw2 = w2;\r\n\t\t\tbestthr = dotthr;\r\n\t\t}\r\n\t}\r\n\r\n\treturn {\r\n\t\tw1: bestw1,\r\n\t\tw2: bestw2,\r\n\t\tdotthr: bestthr\r\n\t};\r\n}\r\n\r\n// returns label for a single data instance\r\nfunction decision2DStumpTest(inst, model) {\r\n\tif (!model) {\r\n\t\t// this is a leaf that never received any data...\r\n\t\treturn 1;\r\n\t}\r\n\treturn inst[0] * model.w1 + inst[1] * model.w2 < model.dotthr ? 1 : -1;\r\n}\r\n\r\n// Misc utility functions\r\nfunction entropy(labels, ix) {\r\n\tlet N = ix.length;\r\n\tlet p = 0.0;\r\n\tfor (let i = 0; i < N; i++) {\r\n\t\tif (labels[ix[i]] === 1) p += 1;\r\n\t}\r\n\tp = (1 + p) / (N + 2); // let's be bayesian about this\r\n\tlet q = (1 + N - p) / (N + 2);\r\n\treturn -p * Math.log(p) - q * Math.log(q);\r\n}\r\n\r\n// generate random floating point number between a and b\r\nfunction randf(a, b) {\r\n\treturn Math.random() * (b - a) + a;\r\n}\r\n\r\n// generate random integer between a and b (b excluded)\r\nfunction randi(a, b) {\r\n\treturn Math.floor(Math.random() * (b - a) + a);\r\n}\r\n\n\n//# sourceURL=webpack:///./src/js/randf/randf.js?");

/***/ }),

/***/ "./src/js/rbf/rbf.js":
/*!***************************!*\
  !*** ./src/js/rbf/rbf.js ***!
  \***************************/
/*! exports provided: RBF */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RBF\", function() { return RBF; });\nconst RBF = function() {};\r\nRBF.prototype = {\r\n\ttrain: function(data, labels, options) {\r\n\t\tthis.data = data;\r\n\t\tthis.labels = labels;\r\n\t\tthis.options = options;\r\n\t\tthis.epsilon = options.epsilon || 0.1;\r\n\t\tthis.rbfSigma = options.rbfSigma || 0.5;\r\n\t},\r\n\tpredict: function(point) {\r\n\t\treturn (Math.tanh(this.rbf(point) / Math.pow(this.epsilon, 2)) + 1) / 2;\r\n\t},\r\n\tpredictClass: function(point) {\r\n\t\treturn this.rbf(point) > 0 ? 1 : -1;\r\n\t},\r\n\trbf: function(point) {\r\n\t\tlet value = 0;\r\n\t\tfor (let i = 0; i < this.data.length; i++) {\r\n\t\t\tlet s = 0;\r\n\t\t\tfor (let j = 0; j < point.length; j++) s += Math.pow(point[j] - this.data[i][j], 2);\r\n\t\t\tvalue += this.labels[i] * Math.exp(-s / (2.0 * Math.pow(this.rbfSigma, 2))); //extend with 1/(x+1) formula too\r\n\t\t}\r\n\t\treturn value;\r\n\t}\r\n};\r\n\n\n//# sourceURL=webpack:///./src/js/rbf/rbf.js?");

/***/ }),

/***/ "./src/js/svm/kernels.js":
/*!*******************************!*\
  !*** ./src/js/svm/kernels.js ***!
  \*******************************/
/*! exports provided: makePolyKernel, makeSigmoidKernel, makeRbfKernel, linearKernel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"makePolyKernel\", function() { return makePolyKernel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"makeSigmoidKernel\", function() { return makeSigmoidKernel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"makeRbfKernel\", function() { return makeRbfKernel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"linearKernel\", function() { return linearKernel; });\n// Kernels\r\n\r\nfunction makePolyKernel(d,c){\r\n    return function(v1, v2){\r\n        let s=0;\r\n        for(let q=0;q<v1.length;q++) { s += v1[q] * v2[q]; }\r\n        s = s+c;\r\n        return Math.pow(s,d);\r\n    }\r\n}\r\n\r\nfunction makeSigmoidKernel(c){\r\n    return function(v1, v2){\r\n        let s=0;\r\n        for(let q=0;q<v1.length;q++) { s += v1[q] * v2[q]; }\r\n        s = s+c;\r\n        return Math.tanh(s);\r\n    }\r\n}\r\n\r\nfunction makeRbfKernel(sigma) {\r\n    return function(v1, v2) {\r\n        let s=0;\r\n        for(let q=0;q<v1.length;q++) { s += (v1[q] - v2[q])*(v1[q] - v2[q]); }\r\n        return Math.exp(-s/(2.0*sigma*sigma));\r\n    }\r\n}\r\n\r\nfunction linearKernel(v1, v2) {\r\n    let s=0;\r\n    for(let q=0;q<v1.length;q++) { s += v1[q] * v2[q]; }\r\n    return s;\r\n}\n\n//# sourceURL=webpack:///./src/js/svm/kernels.js?");

/***/ }),

/***/ "./src/js/svm/svm.js":
/*!***************************!*\
  !*** ./src/js/svm/svm.js ***!
  \***************************/
/*! exports provided: SVM */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SVM\", function() { return SVM; });\n/* harmony import */ var _kernels_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./kernels.js */ \"./src/js/svm/kernels.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils.js */ \"./src/js/svm/utils.js\");\n\r\n\r\n\r\nconst SVM = function(options) {};\r\n\r\nSVM.prototype = {\r\n\r\n        train: function(data, labels, options) {\r\n            let t0 = performance.now();\r\n            this.t0 = t0;\r\n\r\n            this.data = data;\r\n            this.labels = labels;\r\n\r\n            // parameters\r\n            options = options || {};\r\n            let C = options.C || 1.0; // C value. Decrease for more regularization\r\n            let tol = options.tol || 1e-4; // numerical tolerance. Don't touch unless you're pro\r\n            let alphatol = options.alphatol || 0; // non-support vectors for space and time efficiency are truncated. To guarantee correct result set this to 0 to do no truncating. If you want to increase efficiency, experiment with setting this little higher, up to maybe 1e-4 or so.\r\n            let maxiter = options.maxiter || 10000; // max number of iterations\r\n            let numpasses = options.numpasses || 10; // how many passes over data with no change before we halt? Increase for more precision.\r\n            let SSCA = options.SSCA || false;\r\n            let UB = options.UB || 0.5;\r\n\r\n            this.C = C;\r\n            this.tol = tol;\r\n            this.alphatol = alphatol;\r\n            this.maxiter = maxiter;\r\n            this.numpasses = numpasses;\r\n            this.eps = 1e-3; // for the full implemented SMO algorithm\r\n\r\n            // instantiate kernel according to options. kernel can be given as string or as a custom function\r\n            let kernel = _kernels_js__WEBPACK_IMPORTED_MODULE_0__[\"linearKernel\"];\r\n            this.kernelType = \"linear\";\r\n            if(\"kernel\" in options) {\r\n                if(typeof options.kernel === \"string\") {\r\n                    // kernel was specified as a string. Handle these special cases appropriately\r\n                    if(options.kernel === \"linear\") {\r\n                        this.kernelType = \"linear\";\r\n                        kernel = _kernels_js__WEBPACK_IMPORTED_MODULE_0__[\"linearKernel\"];let input_functions = options.input_functions || null;\r\n                        this.input_transformation = false;\r\n                        if (input_functions !== null && input_functions.length > 0) {\r\n                            this.input_transformation = true;\r\n                            let app = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"copyArray\"](this.data);\r\n                            for (let i = 0; i < this.data.length; i++) {\r\n                                let input_f = (function () {\r\n                                });\r\n                                for (let j = 0; j < input_functions.length; j++) {\r\n                                    input_f = input_functions[j];\r\n                                    app[i] = input_f(app[i]);\r\n                                }\r\n                            }\r\n                            this.data = app;\r\n                        }\r\n                    }\r\n                    if(options.kernel === \"rbf\") {\r\n                        let rbfSigma = options.rbfsigma || 0.5;\r\n                        this.rbfSigma = rbfSigma; // back this up\r\n                        this.kernelType = \"rbf\";\r\n                        kernel = Object(_kernels_js__WEBPACK_IMPORTED_MODULE_0__[\"makeRbfKernel\"])(rbfSigma);\r\n                    }\r\n                    if(options.kernel === \"poly\"){\r\n                        let degree = options.degree || 2;\r\n                        this.degree = degree;\r\n                        let influence = options.influence || 1;\r\n                        if(influence<0) //cannot be negative\r\n                            influence = 0; //setting to zero\r\n                        this.influence = influence;\r\n                        this.kernelType = \"poly\";\r\n                        kernel = Object(_kernels_js__WEBPACK_IMPORTED_MODULE_0__[\"makePolyKernel\"])(degree, influence);\r\n                    }\r\n                    if(options.kernel === \"sigm\"){\r\n                        let influence = options.influence || 1;\r\n                        if(influence<0) //cannot be negative\r\n                            influence = 0; //setting to zero\r\n                        this.influence = influence;\r\n                        this.kernelType = \"sigm\";\r\n                        kernel = Object(_kernels_js__WEBPACK_IMPORTED_MODULE_0__[\"makeSigmoidKernel\"])(influence);\r\n                    }\r\n                }\r\n                else {\r\n                    // assume kernel was specified as a function. Let's just use it\r\n                    this.kernelType = \"custom\";\r\n                    kernel = options.kernel;\r\n                }\r\n            }\r\n\r\n            //kernel choice\r\n            this.kernel = kernel;\r\n            //initializations\r\n            this.N = this.data.length;\r\n            this.D = this.data[0].length;\r\n            this.alpha = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"zeros\"](this.N);\r\n            this.b = 0.0;\r\n            this.usew_ = false; // internal efficiency flag\r\n\r\n            this.use_timer = options.timer !== null;\r\n\r\n            if(this.use_timer) {\r\n                this.ctx = options.timer.ctx || null;\r\n                this.updateFrequency = options.timer.updateFrequency || null;\r\n                this.stepsFrequency = options.timer.stepsFrequency || null;\r\n            }\r\n\r\n            // Cache kernel computations to avoid expensive recomputation.\r\n            // This could use too much memory if N is large.\r\n            if (options.memoize) {\r\n                this.kernelResults = new Array(this.N);\r\n                for (let i=0;i<this.N;i++) {\r\n                    this.kernelResults[i] = new Array(this.N);\r\n                    for (let j=0;j<this.N;j++) {\r\n                        this.kernelResults[i][j] = this.kernel(data[i],data[j]);\r\n                    }\r\n                }\r\n            }\r\n\r\n            this.karpathy = options.karpathy || false;\r\n            if(this.karpathy){\r\n                // run SMO algorithm\r\n                this.iter = 0;\r\n                this.passes = 0;\r\n\r\n                if(options.timer){\r\n                    this.timerKarpathySMO();\r\n                }\r\n                else{\r\n                    this.karpathySMO();\r\n                    this.store();\r\n                    let t1 = performance.now();\r\n                    return t1-t0;\r\n                }\r\n            }\r\n            else {\r\n                //FULL Sequential Minimal Optimization (J.Platt)\r\n                //find non-pruned solution for SVM\r\n                this.SMO();\r\n\r\n                //Smoothed Separable Case Approximation\r\n                if(SSCA){\r\n                    this.SSCA(UB,options);\r\n                    this.SMO();\r\n                }\r\n                this.store();\r\n                let t1 = performance.now();\r\n                return t1-t0;\r\n            }\r\n\r\n        },\r\n\r\n        karpathySMO: function(){\r\n            while(this.passes < this.numpasses && this.iter < this.maxiter) {\r\n                this.karpathySMOtime();\r\n            }\r\n        },\r\n\r\n        timerKarpathySMO: function(){\r\n            let weights = [];\r\n            let updateFrequency = this.updateFrequency;\r\n            let stepsFrequency = this.stepsFrequency;\r\n            this.timerVar = setInterval(()=>{\r\n                if(this.passes < this.numpasses && this.iter < this.maxiter){\r\n                    let times = 0;\r\n                    while(this.passes < this.numpasses && this.iter < this.maxiter && times < stepsFrequency) {\r\n                        this.karpathySMOtime();\r\n                        times++;\r\n                    }\r\n                    let w = this.getWeights();\r\n                    weights.push(w);\r\n                    draw();\r\n                    if(!this.input_transformation) {\r\n                        for (let i = 0; i < weights.length; i++)\r\n                            drawIntermidiate(this.ctx, weights[i]);\r\n                    }\r\n                }\r\n                else{\r\n                    clearInterval(this.timerVar);\r\n                    this.store();\r\n                    draw();\r\n                    if(!this.input_transformation) {\r\n                        for (let i = 0; i < weights.length; i++)\r\n                            drawIntermidiate(this.ctx, weights[i]);\r\n                    }\r\n                    console.info( \"🐧 TRAIN end\");\r\n                }\r\n            }, updateFrequency);\r\n        },\r\n\r\n        karpathySMOtime: function(){\r\n            let data = this.data;\r\n            let labels = this.labels;\r\n            let C = this.C;\r\n            let alphaChanged = 0;\r\n            for (let i = 0; i < this.N; i++) {\r\n\r\n                let Ei = this.marginOne(data[i]) - labels[i];\r\n                if ((labels[i] * Ei < -this.tol && this.alpha[i] < C)\r\n                    || (labels[i] * Ei > this.tol && this.alpha[i] > 0)) {\r\n\r\n                    // alpha_i needs updating! Pick a j to update it with\r\n                    let j = i;\r\n                    while (j === i) j = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"randi\"](0, this.N);\r\n                    let Ej = this.marginOne(data[j]) - labels[j];\r\n\r\n                    // calculate L and H bounds for j to ensure we're in [0 C]x[0 C] box\r\n                    let ai = this.alpha[i];\r\n                    let aj = this.alpha[j];\r\n                    let L = 0;\r\n                    let H = C;\r\n                    if (labels[i] === labels[j]) {\r\n                        L = Math.max(0, ai + aj - C);\r\n                        H = Math.min(C, ai + aj);\r\n                    } else {\r\n                        L = Math.max(0, aj - ai);\r\n                        H = Math.min(C, C + aj - ai);\r\n                    }\r\n\r\n                    if (Math.abs(L - H) < 1e-4) continue;\r\n\r\n                    let eta = 2 * this.kernelResult(i, j) - this.kernelResult(i, i) - this.kernelResult(j, j);\r\n                    if (eta >= 0) continue;\r\n\r\n                    // compute new alpha_j and clip it inside [0 C]x[0 C] box\r\n                    // then compute alpha_i based on it.\r\n                    let newaj = aj - labels[j] * (Ei - Ej) / eta;\r\n                    if (newaj > H) newaj = H;\r\n                    if (newaj < L) newaj = L;\r\n                    if (Math.abs(aj - newaj) < 1e-4) continue;\r\n                    this.alpha[j] = newaj;\r\n                    let newai = ai + labels[i] * labels[j] * (aj - newaj);\r\n                    this.alpha[i] = newai;\r\n\r\n                    // update the bias term\r\n                    let b1 = this.b - Ei - labels[i] * (newai - ai) * this.kernelResult(i, i)\r\n                        - labels[j] * (newaj - aj) * this.kernelResult(i, j);\r\n                    let b2 = this.b - Ej - labels[i] * (newai - ai) * this.kernelResult(i, j)\r\n                        - labels[j] * (newaj - aj) * this.kernelResult(j, j);\r\n                    this.b = 0.5 * (b1 + b2);\r\n                    if (newai > 0 && newai < C) this.b = b1;\r\n                    if (newaj > 0 && newaj < C) this.b = b2;\r\n\r\n                    alphaChanged++;\r\n\r\n                } // end alpha_i needed updating\r\n            } // end for i=1..N\r\n            if(this.use_timer)\r\n                this.store();\r\n\r\n            if (alphaChanged === 0) this.passes++;\r\n            else this.passes = 0;\r\n\r\n            this.iter++;\r\n        },\r\n\r\n        store: function(){\r\n            // if the user was using a linear kernel, lets also compute and store the\r\n            // weights. This will speed up evaluations during testing time\r\n            if(this.kernelType === \"linear\" || (this.kernelType === \"poly\" &&  this.degree === 1)) {\r\n\r\n                // compute weights and store them\r\n                this.w = new Array(this.D);\r\n                let s;\r\n                for(let j=0;j<this.D;j++) {\r\n                    s=0;\r\n                    for(let i=0;i<this.data.length;i++) {\r\n                        s += this.alpha[i] * this.labels[i] * this.data[i][j];\r\n                    }\r\n                    this.w[j] = s;\r\n                    this.usew_ = true;\r\n                }\r\n\r\n            }\r\n            else {\r\n                // okay, we need to retain all the support vectors in the training data,\r\n                // we can't just get away with computing the weights and throwing it out\r\n\r\n                // But! We only need to store the support vectors for evaluation of testing\r\n                // instances. So filter here based on this.alpha[i]. The training data\r\n                // for which this.alpha[i] = 0 is irrelevant for future.\r\n                let newdata = [];\r\n                let newlabels = [];\r\n                let newalpha = [];\r\n                for(let i=0;i<this.N;i++) {\r\n                    if(this.alpha[i] > this.alphatol) { //only if they are useful\r\n                        newdata.push(this.data[i]);\r\n                        newlabels.push(this.labels[i]);\r\n                        newalpha.push(this.alpha[i]);\r\n                    }\r\n                }\r\n\r\n                // store data and labels\r\n                this.data = newdata;\r\n                this.labels = newlabels;\r\n                this.alpha = newalpha;\r\n                this.N = this.data.length;\r\n            }\r\n        },\r\n\r\n        update: function(){\r\n            // update value\r\n            this.N = this.data.length;\r\n            this.D = this.data[0].length;\r\n\r\n        },\r\n\r\n        getMaxMargin(data){\r\n            let margins = this.margins(data);\r\n            let max = 0;\r\n            for(let i=0;i<margins.length;i++){\r\n                if(margins[i]>max){\r\n                    max = Math.abs(margins[i]);\r\n                }\r\n            }\r\n            return max;\r\n        },\r\n\r\n        getMinMargin(data){\r\n            let margins = this.margins(data);\r\n            let min = 0;\r\n            for(let i=0;i<margins.length;i++){\r\n                if(margins[i]<min){\r\n                    min = margins[i];\r\n                }\r\n            }\r\n            return min;\r\n        },\r\n\r\n        getFormulaLinear: function(wb){\r\n            let formula = \"\";\r\n            let value = 0;\r\n            let text = \"\";\r\n            let equation = \"\";\r\n            let res = {\r\n            html: \"\",\r\n            text: \"\",\r\n            equation: \"\"\r\n            };\r\n            let intro = \"f(\";\r\n            for(let i=0;i<wb.w.length;i++){\r\n                intro +=\"x\"+\"<sub>\"+i+\"</sub>\";\r\n                if(i<wb.w.length-1)\r\n                    intro+=\",\";\r\n            }\r\n            intro +=\"): \";\r\n            for(let i=0;i<wb.w.length;i++){\r\n            value = wb.w[i].toPrecision(6);\r\n            if(value > 0) {\r\n                formula += \"+\" + value;\r\n                text += \"+\" + value;\r\n                equation += \"+\" +value;\r\n            }\r\n            else {\r\n                formula += value;\r\n                text += value;\r\n                equation += +value;\r\n            }\r\n            formula += \"*<strong>x\"+\"<sub>\"+i+\"</sub>\"+\"</strong>\";\r\n            text += \"*x\"+i;\r\n            equation += \"*x\"+i;\r\n        }\r\n\r\n        if(wb.b > 0) {\r\n            formula += \"+\" + wb.b.toPrecision(6);\r\n            text += \"+\" + wb.b.toPrecision(6);\r\n            equation += \"+\" + wb.b.toPrecision(6);\r\n        }\r\n        else {\r\n            formula += \"\" + wb.b.toPrecision(6);\r\n            text += \"\" + wb.b.toPrecision(6);\r\n            equation += \"\" + wb.b.toPrecision(6)+\"=0\";\r\n        }\r\n        res.html = \"<strong>\"+intro+\"</strong>\"+formula;\r\n        res.text = text;\r\n        res.equation = equation;\r\n        return res;\r\n        },\r\n\r\n        // inst is an array of length D. Returns margin of given example\r\n        // this is the core prediction function. All others are for convenience mostly\r\n        // and end up calling this one somehow.\r\n        marginOne: function(inst) {\r\n            //console.info(\"marginOne\");\r\n            let f = 0;\r\n            if(this.karpathy)\r\n                f = this.b;\r\n            else f = -this.b;\r\n            // if the linear kernel was used and w was computed and stored,\r\n            // (i.e. the svm has fully finished training)\r\n            // the internal class variable usew_ will be set to true.\r\n            if(this.usew_) { //only with linear kernel\r\n                // we can speed this up a lot by using the computed weights\r\n                // we computed these during train(). This is significantly faster\r\n                // than the version below\r\n                for(let j=0;j<this.D;j++) {\r\n                    f += inst[j] * this.w[j];\r\n                }\r\n            }\r\n            else { // others kernel or not already finished computing the weights\r\n                for(let i=0;i<this.data.length;i++) { //for every data entry (N times)\r\n                    f += this.alpha[i] * this.labels[i] * this.kernel(inst, this.data[i]); //sum of all these product, including kernel evaluation with\r\n                }\r\n            }\r\n\r\n            return f;\r\n        },\r\n\r\n        predictClass: function(inst) {\r\n            return this.marginOne(inst) >= 0 ? 1:-1;\r\n        },\r\n\r\n        predict:  function(inst){\r\n        return ((Math.tanh(this.marginOne(inst)))+1)/2;\r\n        },\r\n\r\n        // data is an NxD array. Returns array of margins.\r\n        margins: function(data) {\r\n\r\n            // go over support vectors and accumulate the prediction.\r\n            const N = data.length;\r\n            let margins = new Array(N);\r\n            for(let i=0;i<N;i++) {\r\n                margins[i] = this.marginOne(data[i]);\r\n            }\r\n            return margins;\r\n\r\n        },\r\n\r\n        //used just for memoize the values calculated from the kernel\r\n        kernelResult: function(i, j) {\r\n            if (this.kernelResults) {\r\n                return this.kernelResults[i][j];\r\n            }\r\n            return this.kernel(this.data[i], this.data[j]);\r\n        },\r\n\r\n        // THIS FUNCTION IS NOW DEPRECATED. WORKS FINE BUT NO NEED TO USE ANYMORE.\r\n        // LEAVING IT HERE JUST FOR BACKWARDS COMPATIBILITY FOR A WHILE.\r\n        // if we trained a linear svm, it is possible to calculate just the weights and the offset\r\n        // prediction is then yhat = sign(X * w + b)\r\n        getWeights: function() {\r\n            //if(this.usew_) return {w: this.w, b:this.b};\r\n            // DEPRECATED\r\n            let D = this.data[0].length;\r\n            let w = new Array(D);\r\n            for(let j=0;j<D;j++) {\r\n                let s= 0.0;\r\n                for(let i=0;i<N;i++) {\r\n                    s+= this.alpha[i] * this.labels[i] * this.data[i][j];\r\n                }\r\n                w[j]= s;\r\n            }\r\n            return {w: w, b: this.b};\r\n        },\r\n\r\n        toJSON: function() {\r\n\r\n            if(this.kernelType === \"custom\") {\r\n                console.log(\"Can't save this SVM because it's using custom, unsupported kernel...\");\r\n                return {};\r\n            }\r\n\r\n            let json = {};\r\n            json.N = this.N;\r\n            json.D = this.D;\r\n            json.b = this.b;\r\n\r\n            json.kernelType = this.kernelType;\r\n            if(this.kernelType === \"linear\") {\r\n                // just back up the weights\r\n                json.w = this.w;\r\n            }\r\n            if(this.kernelType === \"rbf\") {\r\n                // we need to store the support vectors and the sigma\r\n                json.rbfSigma = this.rbfSigma;\r\n                json.data = this.data;\r\n                json.labels = this.labels;\r\n                json.alpha = this.alpha;\r\n            }\r\n            if(this.kernelType === \"poly\"){\r\n                //we need to store the support vectors, the influence and the degree\r\n                json.influence = this.influence;\r\n                json.degree = this.degree;\r\n                json.data = this.data;\r\n                json.labels = this.labels;\r\n                json.alpha = this.alpha;\r\n            }\r\n            return json;\r\n        },\r\n\r\n        fromJSON: function(json) {\r\n\r\n            this.N = json.N;\r\n            this.D = json.D;\r\n            this.b = json.b;\r\n\r\n            this.kernelType = json.kernelType;\r\n            if(this.kernelType === \"linear\") {\r\n\r\n                // load the weights!\r\n                this.w = json.w;\r\n                this.usew_ = true;\r\n                this.kernel = _kernels_js__WEBPACK_IMPORTED_MODULE_0__[\"linearKernel\"]; // this shouldn't be necessary\r\n            }\r\n            else if(this.kernelType === \"rbf\") {\r\n\r\n                // initialize the kernel\r\n                this.rbfSigma = json.rbfSigma;\r\n                this.kernel = Object(_kernels_js__WEBPACK_IMPORTED_MODULE_0__[\"makeRbfKernel\"])(this.rbfSigma);\r\n\r\n                // load the support vectors\r\n                this.data = json.data;\r\n                this.labels = json.labels;\r\n                this.alpha = json.alpha;\r\n            }\r\n            else if(this.kernelType === \"poly\") {\r\n\r\n                // initialize the kernel\r\n                this.degree = json.degree;\r\n                this.influence = json.influence;\r\n                this.kernel = Object(_kernels_js__WEBPACK_IMPORTED_MODULE_0__[\"makePolyKernel\"])(this.degree, this.influence);\r\n\r\n                // load the support vectors\r\n                this.data = json.data;\r\n                this.labels = json.labels;\r\n                this.alpha = json.alpha;\r\n            }\r\n            else {\r\n                console.log(\"ERROR! unrecognized kernel type.\" + this.kernelType);\r\n            }\r\n        },\r\n\r\n        //********** FULL SMO ALGORITHM\r\n\r\n        takeStep: function(i1,i2,i,j){\r\n            //console.info(\"trying taking step with \"+i+\",\"+j);\r\n            if(i === j) return 0; //basta controllare l'indice\r\n            //console.info(\"not equal, go on\");\r\n            let alph1 = this.alpha[i];\r\n            let alph2 = this.alpha[j];\r\n            let y1 = this.labels[i];\r\n            let y2 = this.labels[j];\r\n            let E1 = this.getE(i);\r\n            let E2 = this.getE(j);\r\n            let s = y1*y2;\r\n            //Compute L, H via equations (13) and (14)\r\n            let C = this.C; //utiliy variable\r\n            let L,H;\r\n            if(y1 === y2) {\r\n                L = Math.max(0, alph2+alph1-C);\r\n                H = Math.min(C, alph2+alph1);\r\n            }\r\n            else {\r\n                L = Math.max(0, alph2-alph1);\r\n                H = Math.min(C, C+alph2-alph1);\r\n            }\r\n            //console.info(\"L-H = \"+Math.abs(L-H)+\" < \"+1e-4+\" ?\");\r\n            if(L===H) return 0;\r\n            //console.info(\"no, go on\");\r\n            let k11 =this.kernelResult(i,i);\r\n            let k12 =this.kernelResult(i,j);\r\n            let k22 =this.kernelResult(j,j);\r\n            let eta = k11 + k22 - 2*k12;\r\n\r\n            let a1;\r\n            let a2;\r\n            if(eta > 0){\r\n                a2 = alph2 + y2*(E1-E2)/eta;\r\n                if(a2<L) a2 = L;\r\n                else if(a2>H) a2 = H;\r\n            }\r\n            else{\r\n                //console.info(\"eta <0\");\r\n                let f1 = y1*(E1+this.b)-alph1*this.kernelResult(i,i)-s*alph2*this.kernelResult(i,j);\r\n                let f2 = y2*(E2+this.b)-s*alph1*this.kernelResult(i,j)-alph2*this.kernelResult(j,j);\r\n                let L1 = alph1+s*(alph2-L);\r\n                let H1 = alph1+s*(alph2-H);\r\n                let Lobj = L1*f1-L*f2+0.5*L1*L1*this.kernelResult(i,i)+0.5*L*L*this.kernelResult(j,j)+s*L*L1*this.kernelResult(i,j);\r\n                let Hobj = H1*f1+H*f2+0.5*H1*H1*this.kernelResult(i,i)+0.5*H*H*this.kernelResult(j,j)+s*H*H1*this.kernelResult(i,j);\r\n\r\n                if(Lobj < Hobj-this.eps)\r\n                    a2 = L;\r\n                else if( Lobj > Hobj+this.eps)\r\n                    a2 = H;\r\n                else\r\n                    a2 = alph2;\r\n                //this.alpha[i] = value; //risetto il valore a quello di prima\r\n            }\r\n            //console.info(\"a2-alph2 = \"+Math.abs(a2-alph2)+\" < \"+this.eps*(a2+alph2+this.eps)+\" ?\");\r\n            if(Math.abs(a2-alph2)<this.eps*(a2+alph2+this.eps))\r\n                return 0;\r\n            //console.info(\"No,you're done\");\r\n            a1 = alph1+s*(alph2-a2);\r\n\r\n            //console.info(\"updating\");\r\n            //Update threshold to reflect change in Lagrange multipliers\r\n            let b1 = this.b + E1 + y1*(a1-alph1)*this.kernelResult(i,i) + y2*(a2-alph2)*this.kernelResult(i,j);\r\n            let b2 = this.b + E2 + y1*(a1-alph1)*this.kernelResult(i,j) + y2*(a2-alph2)*this.kernelResult(j,j);\r\n            this.b = 0.5*(b1+b2);\r\n            if(a1 > 0 && a1 < C) this.b = b1;\r\n            if(a2 > 0 && a2 < C) this.b = b2;\r\n\r\n            if(this.kernelType === \"linear\") {\r\n                //console.info(\"store weights\");\r\n                // compute weights and store them\r\n                let D = this.data[0].length;\r\n                this.w = new Array(D);\r\n                for(let j=0;j<D;j++) {\r\n                    let s=0.0;\r\n                    for(let i=0;i<this.data.length;i++) {\r\n                        s += this.alpha[i] * this.labels[i] * this.data[i][j];\r\n                    }\r\n                    this.w[j] = s;\r\n                    this.usew_ = true;\r\n                }\r\n            }\r\n            //Update error cache using new Lagrande multipliers\r\n            //************not implemented caching\r\n\r\n            //Store a1 in the alpha array\r\n            this.alpha[i] = a1;\r\n            //Store a2 in the alpha array\r\n            this.alpha[j] = a2;\r\n            //console.info(\"step taken\");\r\n            return 1;\r\n\r\n        },\r\n\r\n        notAtBoundsAlpha: function(){\r\n            let indexes = [];\r\n            for(let i=0;i<this.alpha.length;i++){\r\n                if(!this.isAtBounds(this.alpha[i]))\r\n                    indexes.push(i);\r\n            }\r\n            return indexes;\r\n        },\r\n\r\n        isAtBounds: function(value){\r\n            return value === 0 || value === this.C;\r\n        },\r\n\r\n        getE: function(i){\r\n            return this.marginOne(this.data[i]) - this.labels[i];\r\n        },\r\n\r\n        getMaxStepAlpha: function(i){\r\n            let index = 0;\r\n            let E1 = this.getE(i);\r\n            //let E = new Array(this.data.length);\r\n            let E = [];\r\n            for(let j=0;j<this.data.length;j++){ //fill E vector\r\n                E.push(this.getE(i));\r\n            }\r\n            if(E1 > 0){ //if positive, find the min\r\n                let min = E[0];\r\n                for(let j=0;j<E.length;j++){ //sort the best\r\n                    if(j!==i){\r\n                        if(min>E[j]) {\r\n                            index = j; // save the index\r\n                            min = E[j]; //new min\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n            else{ //non-positive, find the max\r\n                let max = E[0];\r\n                for(let j=0;j<E.length;j++){ //sort the best\r\n                    if(j!==i){\r\n                        if(max<E[j]){\r\n                            index = j; //save the index\r\n                            max = E[j]; //new max\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n\r\n            return index;\r\n        },\r\n\r\n        examineExample: function(i2, i){\r\n            //console.info(\"examineExample\");\r\n            //let labels = this.labels;\r\n            //let C = this.C;\r\n            //let tol = this.tol;\r\n            //let limit = this.data.length;\r\n            //***************\r\n            let y2 = this.labels[i];\r\n            let alph2 = this.alpha[i];\r\n            let E2 = this.getE(i);\r\n            let r2 = E2*y2;\r\n            let i1;\r\n            if( (r2 < -this.tol && alph2 < this.C) || (r2 > this.tol && alph2 > 0) ) {\r\n                let indexes = this.notAtBoundsAlpha();\r\n                if(indexes.length > 1){ //number of non-zero & non-C alpha > 1\r\n                    let index = this.getMaxStepAlpha(i);\r\n                    i1 = this.data[index];//result of second choice heuristic\r\n                    if(this.takeStep(i1,i2,index,i)){\r\n                        return 1;\r\n                    }\r\n                }\r\n\r\n                let counter=0;\r\n                let rand = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"randi\"](0,indexes.length);\r\n                for(let j=rand;counter<indexes.length;j++){ //loop over all non-zero and non-C alpha, starting at a random point\r\n                    if(j === indexes.length){\r\n                        j=-1;\r\n                        continue; //skip this cycle\r\n                    }\r\n                    i1 = this.data[indexes[j]];\r\n                    if(this.takeStep(i1,i2,j,i))\r\n                        return 1;\r\n\r\n                    counter++;\r\n                }\r\n\r\n                counter = 0;\r\n                rand = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"randi\"](0,this.data.length);\r\n                for(let j=rand;counter<this.data.length;j++){ //loop over all possibile i1, starting at a random point\r\n                    if(j === this.data.length){\r\n                        j=-1;\r\n                        continue; //skip this cycle\r\n                    }\r\n                    i1 = this.data[j];\r\n                    //console.info(\"trying with index: \"+j);\r\n                    if(this.takeStep(i1,i2,j,i))\r\n                        return 1;\r\n                    counter++;\r\n                }\r\n            }\r\n            return 0;\r\n        },\r\n\r\n        /**\r\n         * @return {number}\r\n         */\r\n        SMO: function () {\r\n            console.info(\"🐻 SMO (Platt): \"+this.data.length);\r\n            this.update();\r\n            //let statistics = {};\r\n            if(this.N === 0) return 0; // statistics;\r\n            let numChanged  = 0;\r\n            let examineAll = 1;\r\n            this.iter = 0;\r\n            this.N = this.data.length; //length of training examples\r\n\r\n            while(numChanged > 0 || examineAll){ //outer loop\r\n                numChanged = 0;\r\n                if(examineAll){\r\n                    for (let i=0;i<this.N;i++){ //loop over all training examples\r\n                        numChanged += this.examineExample(this.data[i],i);\r\n                    }\r\n                }\r\n                else {\r\n                    for (let i=0;i<this.N;i++){ //loop over examples\r\n                        if(!this.isAtBounds(this.alpha[i])){//where alpha is not 0 & not C\r\n                            numChanged += this.examineExample(this.data[i],i);\r\n                        }\r\n                    }\r\n                }\r\n                if(examineAll === 1)\r\n                    examineAll = 0;\r\n                else if( numChanged === 0)\r\n                    examineAll = 1;\r\n                this.iter++;\r\n            }\r\n\r\n            /*\r\n            //run statistics evaluation\r\n            statistics = statisticEval(this.labels,this.predict(this.data));\r\n            statistics.data = this.data;\r\n            statistics.labels = this.labels;\r\n            statistics.iters = iter;\r\n            */\r\n\r\n            this.ROC();\r\n\r\n            //this.check();\r\n\r\n            console.info(\"🐻 SMO end\");\r\n\r\n            //return statistics;\r\n        },\r\n\r\n        findMaxDistance: function(){\r\n            let max = this.marginOne(this.data[0]);\r\n            let value=0;\r\n            for(let i=0;i<this.data.length;i++){\r\n                value = Math.abs(this.marginOne(this.data[i]));\r\n                if(value > max){\r\n                    max = value;\r\n                }\r\n            }\r\n            return max;\r\n        },\r\n\r\n        /*\r\n        @TODO: Set up a better probability distribution function\r\n        */\r\n        logisticValue: function(x,L){\r\n            let k = 1;\r\n            let exponent = -k*(x);\r\n            return L / (1 + (Math.exp(exponent)));\r\n        },\r\n\r\n        assignProbabilities: function(){\r\n            let rich_data = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"zeros\"](this.data.length);\r\n            let value=0;\r\n            for(let i=0;i<this.data.length;i++){\r\n                let inst = {};\r\n                inst.instance = this.data[i];\r\n                inst.class = this.labels[i];\r\n                value = this.marginOne(this.data[i]);\r\n                inst.score = (Math.tanh(value)+1)/2;\r\n                rich_data[i] = inst;\r\n            }\r\n            //sorting for max\r\n            rich_data.sort(function(a, b){return a.score-b.score}); //ascending order\r\n            rich_data.reverse(); //descending order\r\n            // console.table(rich_data);\r\n            return rich_data; //contains data[i], labels[i] and score[i], ordered by \"score\"\r\n        },\r\n\r\n        getProbsCM: function(threshold,data){\r\n            let CM = [[0,0],[0,0]];\r\n            for(let i=0;i<data.length;i++){\r\n                if(threshold>data[i].score){ //predicted positive with probability\r\n                    if(data[i].class === 1){ //is positive\r\n                        CM[0][0]++;\r\n                    }\r\n                    else{ //is negative (false positive)\r\n                        CM[0][1]++;\r\n                    }\r\n                }\r\n                else{ //predicted negative with probability\r\n                    if(data[i].class === 1){ //is positive (false negative)\r\n                        CM[1][0]++;\r\n                    }\r\n                    else{ //is negative\r\n                        CM[1][1]++;\r\n                    }\r\n                }\r\n            }\r\n            return CM;\r\n        },\r\n\r\n        ROC: function(){\r\n            console.info(\"\\tROC curve\");\r\n            let max = this.findMaxDistance(); //unique\r\n            let rich_data = this.assignProbabilities(); //unique\r\n            let step = 0.01;\r\n            let curve = []; //Array of pair(s)\r\n            let tp,fp,fn,tn,tpr,fpr,cm;\r\n            for(let i=0.0;i<=1;i+=step){\r\n                cm = this.getProbsCM(i,rich_data);\r\n                tp = cm[0][0];\r\n                fp = cm[0][1];\r\n                fn = cm[1][0];\r\n                tn = cm[1][1];\r\n                fpr = fp/(fp+tn);\r\n                tpr = tp/(tp+fn);\r\n                let pair = [fpr,tpr];\r\n                /*\r\n                @TODO: Calculate the coords of the ROC function\r\n                * */\r\n                curve.push(pair);\r\n            }\r\n            console.table(curve);\r\n        },\r\n\r\n        /*\r\n        // compose the Confusion Matrix\r\n        statisticEval:function(){\r\n\r\n        let CM =[[0,0],[0,0]];\r\n        let value = 0;\r\n        let total = this.data.length;\r\n        console.info(\"EVALUATE STATISTICS: \"+total+\"🐢\");\r\n        for(let i=0;i<total;i++){\r\n            value = this.marginOne(this.data[i]); //evaluation\r\n            //console.info(value);\r\n            if(value>0){ //predicted positive\r\n            if(this.labels[i]===1) { //is positive\r\n                CM[0][0]++;\r\n                //console.info(i+\" -> tp\");\r\n            }\r\n            else{ //is negative\r\n                CM[0][1]++;\r\n    //              console.info(i+\" -> fp\");\r\n            }\r\n            }\r\n            else{ //predicted negative\r\n            if(this.labels[i]===1) { //is positive\r\n                CM[1][0]++;\r\n    //              console.info(i+\" -> fn\");\r\n            }\r\n            else{ //is negative\r\n                CM[1][1]++;\r\n    //              console.info(i+\" -> tn\");\r\n            }\r\n            }\r\n        }\r\n        //console.info(\"Confusion Matrix\");\r\n        //console.table(CM);\r\n\r\n        let tp,tn,fp,fn,P,N;\r\n        tp = CM[0][0];\r\n        tn = CM[1][1];\r\n        fp = CM[0][1];\r\n        fn = CM[1][0];\r\n        P = tp+fp;\r\n        N = tn+fn;\r\n        //precision\r\n        let precision = tp/(P);\r\n        if(P===0)\r\n            precision = 0;\r\n        //recall/sensitivity\r\n        let recall = tp/(tp+fn);\r\n        if((tp+fn)===0)\r\n            recall = 0;\r\n        //accurancy\r\n        let accurancy = (tp+tn)/(P+N);\r\n        if((P+N)===0)\r\n            accurancy = 0;\r\n        //specificity\r\n        let specificity = (tn/(N));\r\n        if(N===0)\r\n            specificity = 0;\r\n        //F-measure\r\n        let fMeasure = 2*(precision*recall)/(precision+recall);\r\n        if((precision+recall) === 0)\r\n            fMeasure = 0;\r\n\r\n        //statistic object\r\n        let statistic = {};\r\n        statistic.CM = CM;\r\n        statistic.recall = recall;\r\n        statistic.precision = precision;\r\n        statistic.accurancy = accurancy;\r\n        statistic.specificity = specificity;\r\n        statistic.fMeasure = fMeasure;\r\n        return statistic;\r\n        },\r\n        */\r\n\r\n        //********** SSCA\r\n        //********* Smoothed Separable Case Approximation\r\n\r\n        ruleA: function(i,labels){\r\n            console.info(\"ruleA\");\r\n            labels[i] = -labels[i];\r\n        },\r\n\r\n        ruleB: function(i,data,alpha,labels){\r\n            console.info(\"ruleB element: \"+i);\r\n            data.splice(i,1);\r\n            alpha.splice(i,1);\r\n            labels.splice(i,1);\r\n        },\r\n\r\n        marginSSCA: function(inst,data,alpha,labels){\r\n            let f = -this.b;\r\n            for(let i=0;i<data.length;i++) { //for every data entry (N times)\r\n                f += alpha[i] * labels[i] * this.kernel(inst, data[i]); //sum of all these product, including kernel evaluation with\r\n            }\r\n            return f;\r\n        },\r\n\r\n        SSCA: function (D,options) {\r\n            console.info(\"🍀 SSCA: \"+this.data.length);\r\n            let value;\r\n\r\n            let alpha = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"copyArray\"](this.alpha);\r\n            let labels = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"copyArray\"](this.labels);\r\n            let data = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"copyArray\"](this.data);\r\n            let left = this.data.length;\r\n\r\n            //check conditions for rules A,B\r\n            for (let i = 0; i < left; i++) { //per N volte\r\n\r\n                value = this.marginSSCA(data[i],data,alpha,labels) * labels[i];\r\n                //SCA\r\n                if (value < 0) { //misclassified\r\n                    this.ruleA(i,labels); //flip label\r\n                    value = this.marginSSCA(data[i],data,alpha,labels) * labels[i];\r\n\r\n                    if (value < 0) { //misclassified\r\n                        console.info(\"i:\" + i);\r\n                        this.ruleB(i,data,alpha,labels);\r\n                        i--;\r\n                        left--;\r\n                        continue; //vado avanti\r\n                    }\r\n                }\r\n                //SSCA\r\n                if (value < D) { //misclassified if it's under a threshold D\r\n                    console.info(\"under \" + D);\r\n                    this.ruleB(i,data,alpha,labels);\r\n                    i--;\r\n                    left--;\r\n                }\r\n            }\r\n\r\n            this.data = data;\r\n            this.alpha = alpha;\r\n            this.labels = labels;\r\n\r\n            this.check();\r\n\r\n            options.SSCA = false; //not SSCA again after training\r\n            console.info(\"🍀 SSCA end\");\r\n        },\r\n\r\n        check: function () {\r\n            console.info(\"\\t🔍 CHECK\");\r\n            let value = 0;\r\n            let noOne = true;\r\n            for (let i = 0; i < this.data.length; i++) { //per tutti quelli che devo eliminare\r\n                value = this.marginOne(this.data[i]) * this.labels[i];\r\n                if (value < 0){ //still misclassified with this configuration\r\n                    noOne = false;\r\n                    console.info(\"\\t💀 \"+i+\":\" + value);\r\n                }\r\n            }\r\n            if(noOne) console.info(\"\\t✔️\");\r\n        }\r\n\r\n};\r\n\n\n//# sourceURL=webpack:///./src/js/svm/svm.js?");

/***/ }),

/***/ "./src/js/svm/utils.js":
/*!*****************************!*\
  !*** ./src/js/svm/utils.js ***!
  \*****************************/
/*! exports provided: randf, randi, zeros, copyArray, arrayWith, objectToArray, arrayToObject */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"randf\", function() { return randf; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"randi\", function() { return randi; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"zeros\", function() { return zeros; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"copyArray\", function() { return copyArray; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"arrayWith\", function() { return arrayWith; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"objectToArray\", function() { return objectToArray; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"arrayToObject\", function() { return arrayToObject; });\n\r\nfunction randf(a, b) {\r\n    return Math.random()*(b-a)+a;\r\n}\r\n\r\n// generate random integer between a and b (b excluded)\r\nfunction randi(a, b) {\r\n    return Math.floor(Math.random()*(b-a)+a);\r\n}\r\n\r\n// create vector of zeros of length n\r\nfunction zeros(n) {\r\n    let arr= new Array(n);\r\n    for(let i=0;i<n;i++) { arr[i]= 0; }\r\n    return arr;\r\n}\r\n\r\n//create a copy of the original array\r\nfunction copyArray(v){\r\n    let array = new Array(v.length);\r\n    for(let i=0;i<v.length;i++){\r\n        array[i] = v[i];\r\n    }\r\n    return array;\r\n}\r\n\r\n//create an array based on copy of the value passed from input\r\nfunction arrayWith(value,N){\r\n    let array = new Array(N);\r\n    for(let i=0;i<N;i++){\r\n        array[i] = value;\r\n    }\r\n    return array;\r\n}\r\n\r\nfunction objectToArray(array){\r\n    let result = [];\r\n    array.forEach((data)=>result.push([data.x,data.y]));\r\n    return result;\r\n}\r\n\r\nfunction arrayToObject(array){\r\n    let result = [];\r\n    array.forEach((data)=>result.push({x:data[0],y:data[1]}));\r\n    return result;\r\n}\n\n//# sourceURL=webpack:///./src/js/svm/utils.js?");

/***/ })

/******/ });